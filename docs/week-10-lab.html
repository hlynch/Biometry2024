<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>19 Week 10 Lab | Biometry Lecture and Lab Notes</title>
  <meta name="description" content="19 Week 10 Lab | Biometry Lecture and Lab Notes" />
  <meta name="generator" content="bookdown 0.37 and GitBook 2.6.7" />

  <meta property="og:title" content="19 Week 10 Lab | Biometry Lecture and Lab Notes" />
  <meta property="og:type" content="book" />
  
  
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="19 Week 10 Lab | Biometry Lecture and Lab Notes" />
  
  
  

<meta name="author" content="Heather Lynch" />


<meta name="date" content="2024-01-03" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="week-10-lecture.html"/>
<link rel="next" href="week-11-lecture.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
  
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Biometry Lecture and Lab Notes</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface, data sets, and past exams</a></li>
<li class="chapter" data-level="1" data-path="week-1-lecture.html"><a href="week-1-lecture.html"><i class="fa fa-check"></i><b>1</b> Week 1 Lecture</a>
<ul>
<li class="chapter" data-level="1.1" data-path="week-1-lecture.html"><a href="week-1-lecture.html#week-1-readings"><i class="fa fa-check"></i><b>1.1</b> Week 1 Readings</a></li>
<li class="chapter" data-level="1.2" data-path="week-1-lecture.html"><a href="week-1-lecture.html#basic-outline"><i class="fa fa-check"></i><b>1.2</b> Basic Outline</a></li>
<li class="chapter" data-level="1.3" data-path="week-1-lecture.html"><a href="week-1-lecture.html#todays-agenda"><i class="fa fa-check"></i><b>1.3</b> Today’s Agenda</a></li>
<li class="chapter" data-level="1.4" data-path="week-1-lecture.html"><a href="week-1-lecture.html#basic-probability-theory"><i class="fa fa-check"></i><b>1.4</b> Basic Probability Theory</a>
<ul>
<li class="chapter" data-level="1.4.1" data-path="week-1-lecture.html"><a href="week-1-lecture.html#intersection"><i class="fa fa-check"></i><b>1.4.1</b> Intersection</a></li>
<li class="chapter" data-level="1.4.2" data-path="week-1-lecture.html"><a href="week-1-lecture.html#union"><i class="fa fa-check"></i><b>1.4.2</b> Union</a></li>
</ul></li>
<li class="chapter" data-level="1.5" data-path="week-1-lecture.html"><a href="week-1-lecture.html#multiple-events"><i class="fa fa-check"></i><b>1.5</b> Multiple events</a></li>
<li class="chapter" data-level="1.6" data-path="week-1-lecture.html"><a href="week-1-lecture.html#conditionals"><i class="fa fa-check"></i><b>1.6</b> Conditionals</a></li>
<li class="chapter" data-level="1.7" data-path="week-1-lecture.html"><a href="week-1-lecture.html#a-few-foundational-ideas"><i class="fa fa-check"></i><b>1.7</b> A few foundational ideas</a></li>
<li class="chapter" data-level="1.8" data-path="week-1-lecture.html"><a href="week-1-lecture.html#overview-of-univariate-distributions"><i class="fa fa-check"></i><b>1.8</b> Overview of Univariate Distributions</a></li>
<li class="chapter" data-level="1.9" data-path="week-1-lecture.html"><a href="week-1-lecture.html#what-can-you-ask-of-a-distribution"><i class="fa fa-check"></i><b>1.9</b> What can you ask of a distribution?</a>
<ul>
<li class="chapter" data-level="1.9.1" data-path="week-1-lecture.html"><a href="week-1-lecture.html#expected-value-of-a-random-variable"><i class="fa fa-check"></i><b>1.9.1</b> Expected Value of a Random Variable</a></li>
<li class="chapter" data-level="1.9.2" data-path="week-1-lecture.html"><a href="week-1-lecture.html#discrete-case"><i class="fa fa-check"></i><b>1.9.2</b> Discrete Case</a></li>
<li class="chapter" data-level="1.9.3" data-path="week-1-lecture.html"><a href="week-1-lecture.html#continuous-case"><i class="fa fa-check"></i><b>1.9.3</b> Continuous Case</a></li>
</ul></li>
<li class="chapter" data-level="1.10" data-path="week-1-lecture.html"><a href="week-1-lecture.html#a-brief-introduction-to-inference-logic-and-reasoning"><i class="fa fa-check"></i><b>1.10</b> A brief introduction to inference, logic, and reasoning</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="week-1-lab.html"><a href="week-1-lab.html"><i class="fa fa-check"></i><b>2</b> Week 1 Lab</a>
<ul>
<li class="chapter" data-level="2.1" data-path="week-1-lab.html"><a href="week-1-lab.html#using-r-like-a-calculator"><i class="fa fa-check"></i><b>2.1</b> Using R like a calculator</a></li>
<li class="chapter" data-level="2.2" data-path="week-1-lab.html"><a href="week-1-lab.html#the-basic-data-structures-in-r"><i class="fa fa-check"></i><b>2.2</b> The basic data structures in R</a></li>
<li class="chapter" data-level="2.3" data-path="week-1-lab.html"><a href="week-1-lab.html#writing-functions-in-r"><i class="fa fa-check"></i><b>2.3</b> Writing functions in R</a></li>
<li class="chapter" data-level="2.4" data-path="week-1-lab.html"><a href="week-1-lab.html#writing-loops-and-ifelse"><i class="fa fa-check"></i><b>2.4</b> Writing loops and if/else</a></li>
<li class="chapter" data-level="2.5" data-path="week-1-lab.html"><a href="week-1-lab.html#pop_vs_sample_var"><i class="fa fa-check"></i><b>2.5</b> (A short diversion) Bias in estimators</a></li>
<li class="chapter" data-level="2.6" data-path="week-1-lab.html"><a href="week-1-lab.html#some-practice-writing-r-code"><i class="fa fa-check"></i><b>2.6</b> Some practice writing R code</a></li>
<li class="chapter" data-level="2.7" data-path="week-1-lab.html"><a href="week-1-lab.html#a-few-final-notes"><i class="fa fa-check"></i><b>2.7</b> A few final notes</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="week-2-lecture.html"><a href="week-2-lecture.html"><i class="fa fa-check"></i><b>3</b> Week 2 Lecture</a>
<ul>
<li class="chapter" data-level="3.1" data-path="week-2-lecture.html"><a href="week-2-lecture.html#week-2-readings"><i class="fa fa-check"></i><b>3.1</b> Week 2 Readings</a></li>
<li class="chapter" data-level="3.2" data-path="week-2-lecture.html"><a href="week-2-lecture.html#todays-agenda-1"><i class="fa fa-check"></i><b>3.2</b> Today’s Agenda</a></li>
<li class="chapter" data-level="3.3" data-path="week-2-lecture.html"><a href="week-2-lecture.html#hypothesis-testing"><i class="fa fa-check"></i><b>3.3</b> Hypothesis testing</a></li>
<li class="chapter" data-level="3.4" data-path="week-2-lecture.html"><a href="week-2-lecture.html#permutation-tests"><i class="fa fa-check"></i><b>3.4</b> Permutation tests</a></li>
<li class="chapter" data-level="3.5" data-path="week-2-lecture.html"><a href="week-2-lecture.html#parameter-estimation"><i class="fa fa-check"></i><b>3.5</b> Parameter estimation</a></li>
<li class="chapter" data-level="3.6" data-path="week-2-lecture.html"><a href="week-2-lecture.html#method-1-non-parametric-bootstrap"><i class="fa fa-check"></i><b>3.6</b> Method #1: Non-parametric bootstrap</a></li>
<li class="chapter" data-level="3.7" data-path="week-2-lecture.html"><a href="week-2-lecture.html#parametric-bootstrap"><i class="fa fa-check"></i><b>3.7</b> Parametric bootstrap</a></li>
<li class="chapter" data-level="3.8" data-path="week-2-lecture.html"><a href="week-2-lecture.html#jackknife"><i class="fa fa-check"></i><b>3.8</b> Jackknife</a></li>
<li class="chapter" data-level="3.9" data-path="week-2-lecture.html"><a href="week-2-lecture.html#jackknife-after-bootstrap"><i class="fa fa-check"></i><b>3.9</b> Jackknife-after-bootstrap</a></li>
<li class="chapter" data-level="3.10" data-path="week-2-lecture.html"><a href="week-2-lecture.html#by-the-end-of-week-2-you-should-understand"><i class="fa fa-check"></i><b>3.10</b> By the end of Week 2, you should understand…</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="week-2-lab.html"><a href="week-2-lab.html"><i class="fa fa-check"></i><b>4</b> Week 2 Lab</a>
<ul>
<li class="chapter" data-level="4.1" data-path="week-2-lab.html"><a href="week-2-lab.html#confidence-intervals"><i class="fa fa-check"></i><b>4.1</b> Confidence intervals</a></li>
<li class="chapter" data-level="4.2" data-path="week-2-lab.html"><a href="week-2-lab.html#testing-hypotheses-through-permutation"><i class="fa fa-check"></i><b>4.2</b> Testing hypotheses through permutation</a></li>
<li class="chapter" data-level="4.3" data-path="week-2-lab.html"><a href="week-2-lab.html#basics-of-bootstrap-and-jackknife"><i class="fa fa-check"></i><b>4.3</b> Basics of bootstrap and jackknife</a></li>
<li class="chapter" data-level="4.4" data-path="week-2-lab.html"><a href="week-2-lab.html#calculating-bias-and-standard-error"><i class="fa fa-check"></i><b>4.4</b> Calculating bias and standard error</a></li>
<li class="chapter" data-level="4.5" data-path="week-2-lab.html"><a href="week-2-lab.html#parametric-bootstrap-1"><i class="fa fa-check"></i><b>4.5</b> Parametric bootstrap</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="week-3-lecture.html"><a href="week-3-lecture.html"><i class="fa fa-check"></i><b>5</b> Week 3 Lecture</a>
<ul>
<li class="chapter" data-level="5.1" data-path="week-3-lecture.html"><a href="week-3-lecture.html#week-3-readings"><i class="fa fa-check"></i><b>5.1</b> Week 3 Readings</a></li>
<li class="chapter" data-level="5.2" data-path="week-3-lecture.html"><a href="week-3-lecture.html#overview-of-probability-distributions"><i class="fa fa-check"></i><b>5.2</b> Overview of probability distributions</a></li>
<li class="chapter" data-level="5.3" data-path="week-3-lecture.html"><a href="week-3-lecture.html#normal-gaussian-distribution"><i class="fa fa-check"></i><b>5.3</b> Normal (Gaussian) Distribution</a></li>
<li class="chapter" data-level="5.4" data-path="week-3-lecture.html"><a href="week-3-lecture.html#standard-normal-distribution"><i class="fa fa-check"></i><b>5.4</b> Standard Normal Distribution</a></li>
<li class="chapter" data-level="5.5" data-path="week-3-lecture.html"><a href="week-3-lecture.html#log-normal-distribution"><i class="fa fa-check"></i><b>5.5</b> Log-Normal Distribution</a></li>
<li class="chapter" data-level="5.6" data-path="week-3-lecture.html"><a href="week-3-lecture.html#intermission-central-limit-theorem"><i class="fa fa-check"></i><b>5.6</b> Intermission: Central Limit Theorem</a></li>
<li class="chapter" data-level="5.7" data-path="week-3-lecture.html"><a href="week-3-lecture.html#poisson-distribution"><i class="fa fa-check"></i><b>5.7</b> Poisson Distribution</a></li>
<li class="chapter" data-level="5.8" data-path="week-3-lecture.html"><a href="week-3-lecture.html#binomial-distribution"><i class="fa fa-check"></i><b>5.8</b> Binomial Distribution</a></li>
<li class="chapter" data-level="5.9" data-path="week-3-lecture.html"><a href="week-3-lecture.html#beta-distribution"><i class="fa fa-check"></i><b>5.9</b> Beta Distribution</a></li>
<li class="chapter" data-level="5.10" data-path="week-3-lecture.html"><a href="week-3-lecture.html#gamma-distribution"><i class="fa fa-check"></i><b>5.10</b> Gamma Distribution</a></li>
<li class="chapter" data-level="5.11" data-path="week-3-lecture.html"><a href="week-3-lecture.html#some-additional-notes"><i class="fa fa-check"></i><b>5.11</b> Some additional notes:</a></li>
<li class="chapter" data-level="5.12" data-path="week-3-lecture.html"><a href="week-3-lecture.html#by-the-end-of-week-3-you-should-understand"><i class="fa fa-check"></i><b>5.12</b> By the end of Week 3, you should understand…</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="week-3-lab.html"><a href="week-3-lab.html"><i class="fa fa-check"></i><b>6</b> Week 3 Lab</a>
<ul>
<li class="chapter" data-level="6.1" data-path="week-3-lab.html"><a href="week-3-lab.html#exploring-the-univariate-distributions-with-r"><i class="fa fa-check"></i><b>6.1</b> Exploring the univariate distributions with R</a></li>
<li class="chapter" data-level="6.2" data-path="week-3-lab.html"><a href="week-3-lab.html#standard-deviation-vs.-standard-error"><i class="fa fa-check"></i><b>6.2</b> Standard deviation vs. Standard error</a></li>
<li class="chapter" data-level="6.3" data-path="week-3-lab.html"><a href="week-3-lab.html#the-central-limit-theorem"><i class="fa fa-check"></i><b>6.3</b> The Central Limit Theorem</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="week-4-lecture.html"><a href="week-4-lecture.html"><i class="fa fa-check"></i><b>7</b> Week 4 Lecture</a>
<ul>
<li class="chapter" data-level="7.1" data-path="week-4-lecture.html"><a href="week-4-lecture.html#week-4-readings"><i class="fa fa-check"></i><b>7.1</b> Week 4 Readings</a></li>
<li class="chapter" data-level="7.2" data-path="week-4-lecture.html"><a href="week-4-lecture.html#short-digression-degrees-of-freedom"><i class="fa fa-check"></i><b>7.2</b> Short digression: Degrees of freedom</a></li>
<li class="chapter" data-level="7.3" data-path="week-4-lecture.html"><a href="week-4-lecture.html#t-distribution"><i class="fa fa-check"></i><b>7.3</b> t-distribution</a></li>
<li class="chapter" data-level="7.4" data-path="week-4-lecture.html"><a href="week-4-lecture.html#chi-squared-distribution"><i class="fa fa-check"></i><b>7.4</b> Chi-squared distribution</a></li>
<li class="chapter" data-level="7.5" data-path="week-4-lecture.html"><a href="week-4-lecture.html#f-distribution"><i class="fa fa-check"></i><b>7.5</b> F distribution</a></li>
<li class="chapter" data-level="7.6" data-path="week-4-lecture.html"><a href="week-4-lecture.html#estimating-confidence-intervals---5-special-cases"><i class="fa fa-check"></i><b>7.6</b> Estimating confidence intervals - 5 special cases</a></li>
<li class="chapter" data-level="7.7" data-path="week-4-lecture.html"><a href="week-4-lecture.html#to-recap"><i class="fa fa-check"></i><b>7.7</b> To recap</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="week-4-lab.html"><a href="week-4-lab.html"><i class="fa fa-check"></i><b>8</b> Week 4 Lab</a></li>
<li class="chapter" data-level="9" data-path="week-5-lecture.html"><a href="week-5-lecture.html"><i class="fa fa-check"></i><b>9</b> Week 5 Lecture</a>
<ul>
<li class="chapter" data-level="9.1" data-path="week-5-lecture.html"><a href="week-5-lecture.html#week-5-readings"><i class="fa fa-check"></i><b>9.1</b> Week 5 Readings</a></li>
<li class="chapter" data-level="9.2" data-path="week-5-lecture.html"><a href="week-5-lecture.html#statistical-power"><i class="fa fa-check"></i><b>9.2</b> Statistical power</a></li>
<li class="chapter" data-level="9.3" data-path="week-5-lecture.html"><a href="week-5-lecture.html#the-single-sample-t-test"><i class="fa fa-check"></i><b>9.3</b> The single sample t test</a></li>
<li class="chapter" data-level="9.4" data-path="week-5-lecture.html"><a href="week-5-lecture.html#the-unpaired-two-sample-t-test"><i class="fa fa-check"></i><b>9.4</b> The unpaired two sample t test</a></li>
<li class="chapter" data-level="9.5" data-path="week-5-lecture.html"><a href="week-5-lecture.html#pooledvar"><i class="fa fa-check"></i><b>9.5</b> Pooling the variances</a></li>
<li class="chapter" data-level="9.6" data-path="week-5-lecture.html"><a href="week-5-lecture.html#the-paired-two-sample-t-test"><i class="fa fa-check"></i><b>9.6</b> The paired two sample t test</a></li>
<li class="chapter" data-level="9.7" data-path="week-5-lecture.html"><a href="week-5-lecture.html#the-f-test"><i class="fa fa-check"></i><b>9.7</b> The F test</a></li>
<li class="chapter" data-level="9.8" data-path="week-5-lecture.html"><a href="week-5-lecture.html#comparing-two-proportions"><i class="fa fa-check"></i><b>9.8</b> Comparing two proportions</a></li>
<li class="chapter" data-level="9.9" data-path="week-5-lecture.html"><a href="week-5-lecture.html#comparing-two-distributions"><i class="fa fa-check"></i><b>9.9</b> Comparing two distributions</a></li>
<li class="chapter" data-level="9.10" data-path="week-5-lecture.html"><a href="week-5-lecture.html#a-bit-more-detail-on-the-binomial"><i class="fa fa-check"></i><b>9.10</b> A bit more detail on the Binomial</a></li>
<li class="chapter" data-level="9.11" data-path="week-5-lecture.html"><a href="week-5-lecture.html#side-note-about-the-wald-test"><i class="fa fa-check"></i><b>9.11</b> Side-note about the Wald test</a></li>
<li class="chapter" data-level="9.12" data-path="week-5-lecture.html"><a href="week-5-lecture.html#chi-squared-goodness-of-fit-test"><i class="fa fa-check"></i><b>9.12</b> Chi-squared goodness-of-fit test</a></li>
<li class="chapter" data-level="9.13" data-path="week-5-lecture.html"><a href="week-5-lecture.html#chi-squared-test-of-independence"><i class="fa fa-check"></i><b>9.13</b> Chi-squared test of independence</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="week-5-lab.html"><a href="week-5-lab.html"><i class="fa fa-check"></i><b>10</b> Week 5 Lab</a>
<ul>
<li class="chapter" data-level="10.1" data-path="week-5-lab.html"><a href="week-5-lab.html#f-test"><i class="fa fa-check"></i><b>10.1</b> F-test</a></li>
<li class="chapter" data-level="10.2" data-path="week-5-lab.html"><a href="week-5-lab.html#comparing-two-proportions-1"><i class="fa fa-check"></i><b>10.2</b> Comparing two proportions</a></li>
<li class="chapter" data-level="10.3" data-path="week-5-lab.html"><a href="week-5-lab.html#comparing-two-distributions-1"><i class="fa fa-check"></i><b>10.3</b> Comparing two distributions</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="week-6-lecture.html"><a href="week-6-lecture.html"><i class="fa fa-check"></i><b>11</b> Week 6 Lecture</a>
<ul>
<li class="chapter" data-level="11.1" data-path="week-6-lecture.html"><a href="week-6-lecture.html#week-6-readings"><i class="fa fa-check"></i><b>11.1</b> Week 6 Readings</a></li>
<li class="chapter" data-level="11.2" data-path="week-6-lecture.html"><a href="week-6-lecture.html#family-wise-error-rates"><i class="fa fa-check"></i><b>11.2</b> Family-wise error rates</a></li>
<li class="chapter" data-level="11.3" data-path="week-6-lecture.html"><a href="week-6-lecture.html#how-do-we-sort-the-signal-from-the-noise"><i class="fa fa-check"></i><b>11.3</b> How do we sort the signal from the noise?</a></li>
</ul></li>
<li class="chapter" data-level="12" data-path="week-6-lab.html"><a href="week-6-lab.html"><i class="fa fa-check"></i><b>12</b> Week 6 Lab</a></li>
<li class="chapter" data-level="13" data-path="week-7-lecturelab.html"><a href="week-7-lecturelab.html"><i class="fa fa-check"></i><b>13</b> Week 7 Lecture/Lab</a>
<ul>
<li class="chapter" data-level="13.1" data-path="week-7-lecturelab.html"><a href="week-7-lecturelab.html#week-7-readings"><i class="fa fa-check"></i><b>13.1</b> Week 7 Readings</a></li>
<li class="chapter" data-level="13.2" data-path="week-7-lecturelab.html"><a href="week-7-lecturelab.html#introduction-to-plotting-in-r"><i class="fa fa-check"></i><b>13.2</b> Introduction to plotting in R</a></li>
<li class="chapter" data-level="13.3" data-path="week-7-lecturelab.html"><a href="week-7-lecturelab.html#box-plots"><i class="fa fa-check"></i><b>13.3</b> Box plots</a></li>
<li class="chapter" data-level="13.4" data-path="week-7-lecturelab.html"><a href="week-7-lecturelab.html#two-dimensional-data"><i class="fa fa-check"></i><b>13.4</b> Two-dimensional data</a></li>
<li class="chapter" data-level="13.5" data-path="week-7-lecturelab.html"><a href="week-7-lecturelab.html#three-dimensional-data"><i class="fa fa-check"></i><b>13.5</b> Three-dimensional data</a></li>
<li class="chapter" data-level="13.6" data-path="week-7-lecturelab.html"><a href="week-7-lecturelab.html#multiple-plots"><i class="fa fa-check"></i><b>13.6</b> Multiple plots</a></li>
</ul></li>
<li class="chapter" data-level="14" data-path="week-8-lecture.html"><a href="week-8-lecture.html"><i class="fa fa-check"></i><b>14</b> Week 8 Lecture</a>
<ul>
<li class="chapter" data-level="14.1" data-path="week-8-lecture.html"><a href="week-8-lecture.html#week-8-readings"><i class="fa fa-check"></i><b>14.1</b> Week 8 Readings</a></li>
<li class="chapter" data-level="14.2" data-path="week-8-lecture.html"><a href="week-8-lecture.html#warm-up"><i class="fa fa-check"></i><b>14.2</b> Warm-up</a></li>
<li class="chapter" data-level="14.3" data-path="week-8-lecture.html"><a href="week-8-lecture.html#the-aims-of-modelling-a-discussion-of-shmueli-2010"><i class="fa fa-check"></i><b>14.3</b> The aims of modelling – A discussion of Shmueli (2010)</a></li>
<li class="chapter" data-level="14.4" data-path="week-8-lecture.html"><a href="week-8-lecture.html#introduction-to-linear-models"><i class="fa fa-check"></i><b>14.4</b> Introduction to linear models</a></li>
<li class="chapter" data-level="14.5" data-path="week-8-lecture.html"><a href="week-8-lecture.html#linear-models-example-with-continuous-covariate"><i class="fa fa-check"></i><b>14.5</b> Linear models | example with continuous covariate</a></li>
<li class="chapter" data-level="14.6" data-path="week-8-lecture.html"><a href="week-8-lecture.html#resolving-overparameterization-using-contrasts"><i class="fa fa-check"></i><b>14.6</b> Resolving overparameterization using contrasts</a></li>
<li class="chapter" data-level="14.7" data-path="week-8-lecture.html"><a href="week-8-lecture.html#effect-codingtreatment-constrast"><i class="fa fa-check"></i><b>14.7</b> Effect coding/Treatment constrast</a></li>
<li class="chapter" data-level="14.8" data-path="week-8-lecture.html"><a href="week-8-lecture.html#helmert-contrasts"><i class="fa fa-check"></i><b>14.8</b> Helmert contrasts</a></li>
<li class="chapter" data-level="14.9" data-path="week-8-lecture.html"><a href="week-8-lecture.html#sum-to-zero-contrasts"><i class="fa fa-check"></i><b>14.9</b> Sum-to-zero contrasts</a></li>
<li class="chapter" data-level="14.10" data-path="week-8-lecture.html"><a href="week-8-lecture.html#polynomial-contrasts"><i class="fa fa-check"></i><b>14.10</b> Polynomial contrasts</a></li>
<li class="chapter" data-level="14.11" data-path="week-8-lecture.html"><a href="week-8-lecture.html#visualizing-hypotheses-for-different-coding-schemes"><i class="fa fa-check"></i><b>14.11</b> Visualizing hypotheses for different coding schemes</a></li>
<li class="chapter" data-level="14.12" data-path="week-8-lecture.html"><a href="week-8-lecture.html#orthogonal-vs.-non-orthogonal-contrasts"><i class="fa fa-check"></i><b>14.12</b> Orthogonal vs. Non-orthogonal contrasts</a></li>
<li class="chapter" data-level="14.13" data-path="week-8-lecture.html"><a href="week-8-lecture.html#error-structure-of-linear-models"><i class="fa fa-check"></i><b>14.13</b> Error structure of linear models</a></li>
</ul></li>
<li class="chapter" data-level="15" data-path="week-8-lab.html"><a href="week-8-lab.html"><i class="fa fa-check"></i><b>15</b> Week 8 Lab</a>
<ul>
<li class="chapter" data-level="15.1" data-path="week-8-lab.html"><a href="week-8-lab.html#covariate-as-number-vs.-covariate-as-factor"><i class="fa fa-check"></i><b>15.1</b> Covariate as number vs. covariate as factor</a></li>
<li class="chapter" data-level="15.2" data-path="week-8-lab.html"><a href="week-8-lab.html#helmert-contrasts-in-r"><i class="fa fa-check"></i><b>15.2</b> Helmert contrasts in R</a></li>
<li class="chapter" data-level="15.3" data-path="week-8-lab.html"><a href="week-8-lab.html#polynomial-contrasts-in-r"><i class="fa fa-check"></i><b>15.3</b> Polynomial contrasts in R</a></li>
</ul></li>
<li class="chapter" data-level="16" data-path="week-9-lecture.html"><a href="week-9-lecture.html"><i class="fa fa-check"></i><b>16</b> Week 9 Lecture</a>
<ul>
<li class="chapter" data-level="16.1" data-path="week-9-lecture.html"><a href="week-9-lecture.html#week-9-readings"><i class="fa fa-check"></i><b>16.1</b> Week 9 Readings</a></li>
<li class="chapter" data-level="16.2" data-path="week-9-lecture.html"><a href="week-9-lecture.html#correlation"><i class="fa fa-check"></i><b>16.2</b> Correlation</a></li>
<li class="chapter" data-level="16.3" data-path="week-9-lecture.html"><a href="week-9-lecture.html#hypothesis-testing---pearsons-r"><i class="fa fa-check"></i><b>16.3</b> Hypothesis testing - Pearson’s <em>r</em></a></li>
<li class="chapter" data-level="16.4" data-path="week-9-lecture.html"><a href="week-9-lecture.html#fishers-z"><i class="fa fa-check"></i><b>16.4</b> Fisher’s <span class="math inline">\(z\)</span></a></li>
<li class="chapter" data-level="16.5" data-path="week-9-lecture.html"><a href="week-9-lecture.html#regression"><i class="fa fa-check"></i><b>16.5</b> Regression</a></li>
<li class="chapter" data-level="16.6" data-path="week-9-lecture.html"><a href="week-9-lecture.html#estimating-the-slope-and-intercept-in-linear-regression"><i class="fa fa-check"></i><b>16.6</b> Estimating the slope and intercept in linear regression</a></li>
<li class="chapter" data-level="16.7" data-path="week-9-lecture.html"><a href="week-9-lecture.html#ok-now-the-other-derivation-for-slope-and-intercept"><i class="fa fa-check"></i><b>16.7</b> OK, now the “other” derivation for slope and intercept</a></li>
<li class="chapter" data-level="16.8" data-path="week-9-lecture.html"><a href="week-9-lecture.html#assumptions-of-regression"><i class="fa fa-check"></i><b>16.8</b> Assumptions of regression</a></li>
<li class="chapter" data-level="16.9" data-path="week-9-lecture.html"><a href="week-9-lecture.html#confidence-vs.-prediction-intervals"><i class="fa fa-check"></i><b>16.9</b> Confidence vs. Prediction intervals</a></li>
<li class="chapter" data-level="16.10" data-path="week-9-lecture.html"><a href="week-9-lecture.html#how-do-we-know-if-our-model-is-any-good"><i class="fa fa-check"></i><b>16.10</b> How do we know if our model is any good?</a></li>
<li class="chapter" data-level="16.11" data-path="week-9-lecture.html"><a href="week-9-lecture.html#robust-regression"><i class="fa fa-check"></i><b>16.11</b> Robust regression</a></li>
<li class="chapter" data-level="16.12" data-path="week-9-lecture.html"><a href="week-9-lecture.html#type-i-and-type-ii-regression"><i class="fa fa-check"></i><b>16.12</b> Type I and Type II Regression</a></li>
<li class="chapter" data-level="16.13" data-path="week-9-lecture.html"><a href="week-9-lecture.html#W9FAQ"><i class="fa fa-check"></i><b>16.13</b> Week 9 FAQ</a></li>
</ul></li>
<li class="chapter" data-level="17" data-path="week-9-lab.html"><a href="week-9-lab.html"><i class="fa fa-check"></i><b>17</b> Week 9 Lab</a>
<ul>
<li class="chapter" data-level="17.1" data-path="week-9-lab.html"><a href="week-9-lab.html#correlation-1"><i class="fa fa-check"></i><b>17.1</b> Correlation</a></li>
<li class="chapter" data-level="17.2" data-path="week-9-lab.html"><a href="week-9-lab.html#linear-modelling"><i class="fa fa-check"></i><b>17.2</b> Linear modelling</a></li>
<li class="chapter" data-level="17.3" data-path="week-9-lab.html"><a href="week-9-lab.html#weighted-regression"><i class="fa fa-check"></i><b>17.3</b> Weighted regression</a></li>
<li class="chapter" data-level="17.4" data-path="week-9-lab.html"><a href="week-9-lab.html#robust-regression-1"><i class="fa fa-check"></i><b>17.4</b> Robust regression</a></li>
<li class="chapter" data-level="17.5" data-path="week-9-lab.html"><a href="week-9-lab.html#bootstrapping-standard-errors-for-robust-regression"><i class="fa fa-check"></i><b>17.5</b> Bootstrapping standard errors for robust regression</a></li>
<li class="chapter" data-level="17.6" data-path="week-9-lab.html"><a href="week-9-lab.html#type-i-vs.-type-ii-regression-the-smatr-package"><i class="fa fa-check"></i><b>17.6</b> Type I vs. Type II regression: The ‘smatr’ package</a></li>
</ul></li>
<li class="chapter" data-level="18" data-path="week-10-lecture.html"><a href="week-10-lecture.html"><i class="fa fa-check"></i><b>18</b> Week 10 Lecture</a>
<ul>
<li class="chapter" data-level="18.1" data-path="week-10-lecture.html"><a href="week-10-lecture.html#week-10-readings"><i class="fa fa-check"></i><b>18.1</b> Week 10 Readings</a></li>
<li class="chapter" data-level="18.2" data-path="week-10-lecture.html"><a href="week-10-lecture.html#week-10-outline"><i class="fa fa-check"></i><b>18.2</b> Week 10 outline</a></li>
<li class="chapter" data-level="18.3" data-path="week-10-lecture.html"><a href="week-10-lecture.html#an-example"><i class="fa fa-check"></i><b>18.3</b> An example</a></li>
<li class="chapter" data-level="18.4" data-path="week-10-lecture.html"><a href="week-10-lecture.html#generalized-linear-models"><i class="fa fa-check"></i><b>18.4</b> Generalized linear models</a></li>
<li class="chapter" data-level="18.5" data-path="week-10-lecture.html"><a href="week-10-lecture.html#logistic-regression"><i class="fa fa-check"></i><b>18.5</b> Logistic regression</a></li>
<li class="chapter" data-level="18.6" data-path="week-10-lecture.html"><a href="week-10-lecture.html#fitting-a-glm"><i class="fa fa-check"></i><b>18.6</b> Fitting a GLM</a></li>
<li class="chapter" data-level="18.7" data-path="week-10-lecture.html"><a href="week-10-lecture.html#poisson-regression"><i class="fa fa-check"></i><b>18.7</b> Poisson regression</a></li>
<li class="chapter" data-level="18.8" data-path="week-10-lecture.html"><a href="week-10-lecture.html#deviance"><i class="fa fa-check"></i><b>18.8</b> Deviance</a></li>
<li class="chapter" data-level="18.9" data-path="week-10-lecture.html"><a href="week-10-lecture.html#other-methods-loess-splines-gams"><i class="fa fa-check"></i><b>18.9</b> Other methods – LOESS, splines, GAMs</a></li>
</ul></li>
<li class="chapter" data-level="19" data-path="week-10-lab.html"><a href="week-10-lab.html"><i class="fa fa-check"></i><b>19</b> Week 10 Lab</a>
<ul>
<li class="chapter" data-level="19.1" data-path="week-10-lab.html"><a href="week-10-lab.html#discussion-of-challenger-analysis"><i class="fa fa-check"></i><b>19.1</b> Discussion of Challenger analysis</a></li>
<li class="chapter" data-level="19.2" data-path="week-10-lab.html"><a href="week-10-lab.html#weighted-linear-regression"><i class="fa fa-check"></i><b>19.2</b> Weighted linear regression</a></li>
<li class="chapter" data-level="19.3" data-path="week-10-lab.html"><a href="week-10-lab.html#logistic-regression-practice"><i class="fa fa-check"></i><b>19.3</b> Logistic regression practice</a></li>
<li class="chapter" data-level="19.4" data-path="week-10-lab.html"><a href="week-10-lab.html#poisson-regression-practice"><i class="fa fa-check"></i><b>19.4</b> Poisson regression practice</a></li>
<li class="chapter" data-level="19.5" data-path="week-10-lab.html"><a href="week-10-lab.html#getting-a-feel-for-deviance"><i class="fa fa-check"></i><b>19.5</b> Getting a feel for Deviance</a></li>
<li class="chapter" data-level="19.6" data-path="week-10-lab.html"><a href="week-10-lab.html#generalized-additive-models"><i class="fa fa-check"></i><b>19.6</b> Generalized Additive Models</a></li>
</ul></li>
<li class="chapter" data-level="20" data-path="week-11-lecture.html"><a href="week-11-lecture.html"><i class="fa fa-check"></i><b>20</b> Week 11 Lecture</a>
<ul>
<li class="chapter" data-level="20.1" data-path="week-11-lecture.html"><a href="week-11-lecture.html#week-11-readings"><i class="fa fa-check"></i><b>20.1</b> Week 11 Readings</a></li>
<li class="chapter" data-level="20.2" data-path="week-11-lecture.html"><a href="week-11-lecture.html#week-11-outline"><i class="fa fa-check"></i><b>20.2</b> Week 11 outline</a>
<ul>
<li class="chapter" data-level="20.2.1" data-path="week-11-lecture.html"><a href="week-11-lecture.html#variation-within-treatment-group"><i class="fa fa-check"></i><b>20.2.1</b> Variation within treatment group</a></li>
<li class="chapter" data-level="20.2.2" data-path="week-11-lecture.html"><a href="week-11-lecture.html#variation-among-treatment-group-means"><i class="fa fa-check"></i><b>20.2.2</b> Variation among treatment group means</a></li>
<li class="chapter" data-level="20.2.3" data-path="week-11-lecture.html"><a href="week-11-lecture.html#comparing-variance-components"><i class="fa fa-check"></i><b>20.2.3</b> Comparing variance components</a></li>
</ul></li>
<li class="chapter" data-level="20.3" data-path="week-11-lecture.html"><a href="week-11-lecture.html#comparing-variance-components-1"><i class="fa fa-check"></i><b>20.3</b> Comparing variance components</a></li>
<li class="chapter" data-level="20.4" data-path="week-11-lecture.html"><a href="week-11-lecture.html#two-ways-to-estimate-variance"><i class="fa fa-check"></i><b>20.4</b> Two ways to estimate variance</a></li>
<li class="chapter" data-level="20.5" data-path="week-11-lecture.html"><a href="week-11-lecture.html#single-factor-anova"><i class="fa fa-check"></i><b>20.5</b> Single-factor ANOVA</a></li>
<li class="chapter" data-level="20.6" data-path="week-11-lecture.html"><a href="week-11-lecture.html#fixed-effects-vs.-random-effects"><i class="fa fa-check"></i><b>20.6</b> Fixed effects vs. random effects</a></li>
<li class="chapter" data-level="20.7" data-path="week-11-lecture.html"><a href="week-11-lecture.html#post-hoc-tests"><i class="fa fa-check"></i><b>20.7</b> Post-hoc tests</a>
<ul>
<li class="chapter" data-level="20.7.1" data-path="week-11-lecture.html"><a href="week-11-lecture.html#tukeys-hsd"><i class="fa fa-check"></i><b>20.7.1</b> Tukey’s HSD</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="21" data-path="week-11-lab.html"><a href="week-11-lab.html"><i class="fa fa-check"></i><b>21</b> Week 11 Lab</a>
<ul>
<li class="chapter" data-level="21.1" data-path="week-11-lab.html"><a href="week-11-lab.html#rs-anova-functions"><i class="fa fa-check"></i><b>21.1</b> R’s ANOVA functions</a></li>
<li class="chapter" data-level="21.2" data-path="week-11-lab.html"><a href="week-11-lab.html#single-factor-anova-in-r"><i class="fa fa-check"></i><b>21.2</b> Single-factor ANOVA in R</a></li>
<li class="chapter" data-level="21.3" data-path="week-11-lab.html"><a href="week-11-lab.html#follow-up-analyses-to-anova"><i class="fa fa-check"></i><b>21.3</b> Follow up analyses to ANOVA</a></li>
<li class="chapter" data-level="21.4" data-path="week-11-lab.html"><a href="week-11-lab.html#more-practice-model-i-anova"><i class="fa fa-check"></i><b>21.4</b> More practice: Model I ANOVA</a></li>
<li class="chapter" data-level="21.5" data-path="week-11-lab.html"><a href="week-11-lab.html#more-practice-brief-intro-to-doing-model-ii-anova-in-r"><i class="fa fa-check"></i><b>21.5</b> More practice: Brief intro to doing Model II ANOVA in R</a></li>
</ul></li>
<li class="chapter" data-level="22" data-path="week-12-lecture.html"><a href="week-12-lecture.html"><i class="fa fa-check"></i><b>22</b> Week 12 Lecture</a>
<ul>
<li class="chapter" data-level="22.1" data-path="week-12-lecture.html"><a href="week-12-lecture.html#week-12-readings"><i class="fa fa-check"></i><b>22.1</b> Week 12 Readings</a></li>
<li class="chapter" data-level="22.2" data-path="week-12-lecture.html"><a href="week-12-lecture.html#week-12-outline"><i class="fa fa-check"></i><b>22.2</b> Week 12 outline</a></li>
<li class="chapter" data-level="22.3" data-path="week-12-lecture.html"><a href="week-12-lecture.html#review-anova-with-one-factor"><i class="fa fa-check"></i><b>22.3</b> Review: ANOVA with one factor</a></li>
<li class="chapter" data-level="22.4" data-path="week-12-lecture.html"><a href="week-12-lecture.html#anova-with-more-than-one-factor"><i class="fa fa-check"></i><b>22.4</b> ANOVA with more than one factor</a></li>
<li class="chapter" data-level="22.5" data-path="week-12-lecture.html"><a href="week-12-lecture.html#two-way-anova-factorial-designs"><i class="fa fa-check"></i><b>22.5</b> Two-way ANOVA factorial designs</a></li>
<li class="chapter" data-level="22.6" data-path="week-12-lecture.html"><a href="week-12-lecture.html#why-bother-with-random-effects"><i class="fa fa-check"></i><b>22.6</b> Why bother with random effects?</a></li>
<li class="chapter" data-level="22.7" data-path="week-12-lecture.html"><a href="week-12-lecture.html#mixed-model"><i class="fa fa-check"></i><b>22.7</b> Mixed model</a></li>
<li class="chapter" data-level="22.8" data-path="week-12-lecture.html"><a href="week-12-lecture.html#unbalanced-designs"><i class="fa fa-check"></i><b>22.8</b> Unbalanced designs</a>
<ul>
<li class="chapter" data-level="22.8.1" data-path="week-12-lecture.html"><a href="week-12-lecture.html#unbalanced-design-different-sample-sizes"><i class="fa fa-check"></i><b>22.8.1</b> Unbalanced design – Different sample sizes</a></li>
<li class="chapter" data-level="22.8.2" data-path="week-12-lecture.html"><a href="week-12-lecture.html#type-i-sequential-sums-of-squares"><i class="fa fa-check"></i><b>22.8.2</b> Type I (sequential) sums of squares</a></li>
<li class="chapter" data-level="22.8.3" data-path="week-12-lecture.html"><a href="week-12-lecture.html#type-ii-hierarchical-sums-of-squares"><i class="fa fa-check"></i><b>22.8.3</b> Type II (hierarchical) sums of squares</a></li>
<li class="chapter" data-level="22.8.4" data-path="week-12-lecture.html"><a href="week-12-lecture.html#type-iii-marginal-sums-of-squares"><i class="fa fa-check"></i><b>22.8.4</b> Type III (marginal) sums of squares</a></li>
<li class="chapter" data-level="22.8.5" data-path="week-12-lecture.html"><a href="week-12-lecture.html#comparing-type-i-ii-and-iii-ss"><i class="fa fa-check"></i><b>22.8.5</b> Comparing type I, II, and III SS</a></li>
</ul></li>
<li class="chapter" data-level="22.9" data-path="week-12-lecture.html"><a href="week-12-lecture.html#unbalanced-design-missing-cell"><i class="fa fa-check"></i><b>22.9</b> Unbalanced design – Missing cell</a></li>
<li class="chapter" data-level="22.10" data-path="week-12-lecture.html"><a href="week-12-lecture.html#two-factor-nested-anova"><i class="fa fa-check"></i><b>22.10</b> Two factor nested ANOVA</a>
<ul>
<li class="chapter" data-level="22.10.1" data-path="week-12-lecture.html"><a href="week-12-lecture.html#potential-issues-with-nested-designs"><i class="fa fa-check"></i><b>22.10.1</b> Potential issues with nested designs</a></li>
</ul></li>
<li class="chapter" data-level="22.11" data-path="week-12-lecture.html"><a href="week-12-lecture.html#experimental-design"><i class="fa fa-check"></i><b>22.11</b> Experimental design</a>
<ul>
<li class="chapter" data-level="22.11.1" data-path="week-12-lecture.html"><a href="week-12-lecture.html#completely-randomized-design"><i class="fa fa-check"></i><b>22.11.1</b> Completely randomized design</a></li>
<li class="chapter" data-level="22.11.2" data-path="week-12-lecture.html"><a href="week-12-lecture.html#randomized-block-design"><i class="fa fa-check"></i><b>22.11.2</b> Randomized block design</a></li>
<li class="chapter" data-level="22.11.3" data-path="week-12-lecture.html"><a href="week-12-lecture.html#latin-square-design"><i class="fa fa-check"></i><b>22.11.3</b> Latin square design</a></li>
<li class="chapter" data-level="22.11.4" data-path="week-12-lecture.html"><a href="week-12-lecture.html#split-plot-design"><i class="fa fa-check"></i><b>22.11.4</b> Split plot design</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="23" data-path="week-12-lab.html"><a href="week-12-lab.html"><i class="fa fa-check"></i><b>23</b> Week 12 Lab</a>
<ul>
<li class="chapter" data-level="23.1" data-path="week-12-lab.html"><a href="week-12-lab.html#example-1-two-way-factorial-anova-in-r"><i class="fa fa-check"></i><b>23.1</b> Example #1: Two-way factorial ANOVA in R</a></li>
<li class="chapter" data-level="23.2" data-path="week-12-lab.html"><a href="week-12-lab.html#example-2-nested-design"><i class="fa fa-check"></i><b>23.2</b> Example #2: Nested design</a></li>
<li class="chapter" data-level="23.3" data-path="week-12-lab.html"><a href="week-12-lab.html#example-3-nested-design"><i class="fa fa-check"></i><b>23.3</b> Example #3: Nested design</a></li>
<li class="chapter" data-level="23.4" data-path="week-12-lab.html"><a href="week-12-lab.html#example-4-randomized-block-design"><i class="fa fa-check"></i><b>23.4</b> Example #4: Randomized Block Design</a></li>
<li class="chapter" data-level="23.5" data-path="week-12-lab.html"><a href="week-12-lab.html#example-5-nested-design"><i class="fa fa-check"></i><b>23.5</b> Example #5: Nested design</a></li>
</ul></li>
<li class="chapter" data-level="24" data-path="week-13-lecture.html"><a href="week-13-lecture.html"><i class="fa fa-check"></i><b>24</b> Week 13 Lecture</a>
<ul>
<li class="chapter" data-level="24.1" data-path="week-13-lecture.html"><a href="week-13-lecture.html#week-13-readings"><i class="fa fa-check"></i><b>24.1</b> Week 13 Readings</a></li>
<li class="chapter" data-level="24.2" data-path="week-13-lecture.html"><a href="week-13-lecture.html#model-criticism"><i class="fa fa-check"></i><b>24.2</b> Model criticism</a></li>
<li class="chapter" data-level="24.3" data-path="week-13-lecture.html"><a href="week-13-lecture.html#residuals"><i class="fa fa-check"></i><b>24.3</b> Residuals</a></li>
<li class="chapter" data-level="24.4" data-path="week-13-lecture.html"><a href="week-13-lecture.html#leverage"><i class="fa fa-check"></i><b>24.4</b> Leverage</a></li>
<li class="chapter" data-level="24.5" data-path="week-13-lecture.html"><a href="week-13-lecture.html#influence"><i class="fa fa-check"></i><b>24.5</b> Influence</a></li>
<li class="chapter" data-level="24.6" data-path="week-13-lecture.html"><a href="week-13-lecture.html#comparing-residuals-leverage-and-influence"><i class="fa fa-check"></i><b>24.6</b> Comparing residuals, leverage, and influence</a></li>
<li class="chapter" data-level="24.7" data-path="week-13-lecture.html"><a href="week-13-lecture.html#residuals-for-glms"><i class="fa fa-check"></i><b>24.7</b> Residuals for GLMs</a></li>
<li class="chapter" data-level="24.8" data-path="week-13-lecture.html"><a href="week-13-lecture.html#model-selection-vs.-model-criticism"><i class="fa fa-check"></i><b>24.8</b> Model selection vs. model criticism</a></li>
<li class="chapter" data-level="24.9" data-path="week-13-lecture.html"><a href="week-13-lecture.html#comparing-two-models"><i class="fa fa-check"></i><b>24.9</b> Comparing two models</a>
<ul>
<li class="chapter" data-level="24.9.1" data-path="week-13-lecture.html"><a href="week-13-lecture.html#nested-or-not"><i class="fa fa-check"></i><b>24.9.1</b> Nested or not?</a></li>
<li class="chapter" data-level="24.9.2" data-path="week-13-lecture.html"><a href="week-13-lecture.html#likelihood-ratio-test-lrt"><i class="fa fa-check"></i><b>24.9.2</b> Likelihood Ratio Test (LRT)</a></li>
<li class="chapter" data-level="24.9.3" data-path="week-13-lecture.html"><a href="week-13-lecture.html#akaikes-information-criterion-aic"><i class="fa fa-check"></i><b>24.9.3</b> Akaike’s Information Criterion (AIC)</a></li>
<li class="chapter" data-level="24.9.4" data-path="week-13-lecture.html"><a href="week-13-lecture.html#bayesian-information-criterion-bic"><i class="fa fa-check"></i><b>24.9.4</b> Bayesian Information Criterion (BIC)</a></li>
<li class="chapter" data-level="24.9.5" data-path="week-13-lecture.html"><a href="week-13-lecture.html#comparing-lrt-and-aicbic"><i class="fa fa-check"></i><b>24.9.5</b> Comparing LRT and AIC/BIC</a></li>
</ul></li>
<li class="chapter" data-level="24.10" data-path="week-13-lecture.html"><a href="week-13-lecture.html#model-weighting"><i class="fa fa-check"></i><b>24.10</b> Model weighting</a></li>
<li class="chapter" data-level="24.11" data-path="week-13-lecture.html"><a href="week-13-lecture.html#stepwise-regression"><i class="fa fa-check"></i><b>24.11</b> Stepwise regression</a>
<ul>
<li class="chapter" data-level="24.11.1" data-path="week-13-lecture.html"><a href="week-13-lecture.html#criticism-of-stepwise-regression"><i class="fa fa-check"></i><b>24.11.1</b> Criticism of stepwise regression</a></li>
<li class="chapter" data-level="24.11.2" data-path="week-13-lecture.html"><a href="week-13-lecture.html#criticism-of-data-dredging"><i class="fa fa-check"></i><b>24.11.2</b> Criticism of data dredging</a></li>
<li class="chapter" data-level="24.11.3" data-path="week-13-lecture.html"><a href="week-13-lecture.html#final-thoughts-on-model-selection"><i class="fa fa-check"></i><b>24.11.3</b> Final thoughts on model selection</a></li>
</ul></li>
<li class="chapter" data-level="24.12" data-path="week-13-lecture.html"><a href="week-13-lecture.html#week-13-faq"><i class="fa fa-check"></i><b>24.12</b> Week 13 FAQ</a></li>
</ul></li>
<li class="chapter" data-level="25" data-path="week-13-lab.html"><a href="week-13-lab.html"><i class="fa fa-check"></i><b>25</b> Week 13 Lab</a>
<ul>
<li class="chapter" data-level="25.1" data-path="week-13-lab.html"><a href="week-13-lab.html#part-1-model-selection-model-comparison"><i class="fa fa-check"></i><b>25.1</b> Part 1: Model selection / model comparison</a></li>
<li class="chapter" data-level="25.2" data-path="week-13-lab.html"><a href="week-13-lab.html#model-selection-via-step-wise-regression"><i class="fa fa-check"></i><b>25.2</b> Model selection via step-wise regression</a></li>
<li class="chapter" data-level="25.3" data-path="week-13-lab.html"><a href="week-13-lab.html#part-2-model-criticism"><i class="fa fa-check"></i><b>25.3</b> Part 2: Model criticism</a></li>
</ul></li>
<li class="chapter" data-level="26" data-path="week-14-lecture.html"><a href="week-14-lecture.html"><i class="fa fa-check"></i><b>26</b> Week 14 Lecture</a>
<ul>
<li class="chapter" data-level="26.1" data-path="week-14-lecture.html"><a href="week-14-lecture.html#week-14-readings"><i class="fa fa-check"></i><b>26.1</b> Week 14 Readings</a></li>
<li class="chapter" data-level="26.2" data-path="week-14-lecture.html"><a href="week-14-lecture.html#what-does-multivariate-mean"><i class="fa fa-check"></i><b>26.2</b> What does ‘multivariate’ mean?</a></li>
<li class="chapter" data-level="26.3" data-path="week-14-lecture.html"><a href="week-14-lecture.html#multivariate-associations"><i class="fa fa-check"></i><b>26.3</b> Multivariate associations</a></li>
<li class="chapter" data-level="26.4" data-path="week-14-lecture.html"><a href="week-14-lecture.html#model-criticism-for-multivariate-analyses"><i class="fa fa-check"></i><b>26.4</b> Model criticism for multivariate analyses</a>
<ul>
<li class="chapter" data-level="26.4.1" data-path="week-14-lecture.html"><a href="week-14-lecture.html#transforming-your-data"><i class="fa fa-check"></i><b>26.4.1</b> Transforming your data</a></li>
</ul></li>
<li class="chapter" data-level="26.5" data-path="week-14-lecture.html"><a href="week-14-lecture.html#standardizing-your-data"><i class="fa fa-check"></i><b>26.5</b> Standardizing your data</a></li>
<li class="chapter" data-level="26.6" data-path="week-14-lecture.html"><a href="week-14-lecture.html#multivariate-outliers"><i class="fa fa-check"></i><b>26.6</b> Multivariate outliers</a></li>
<li class="chapter" data-level="26.7" data-path="week-14-lecture.html"><a href="week-14-lecture.html#brief-overview-of-multivariate-analyses"><i class="fa fa-check"></i><b>26.7</b> Brief overview of multivariate analyses</a></li>
<li class="chapter" data-level="26.8" data-path="week-14-lecture.html"><a href="week-14-lecture.html#manova-and-dfa"><i class="fa fa-check"></i><b>26.8</b> MANOVA and DFA</a></li>
<li class="chapter" data-level="26.9" data-path="week-14-lecture.html"><a href="week-14-lecture.html#scaling-or-ordination-techniques"><i class="fa fa-check"></i><b>26.9</b> Scaling or ordination techniques</a></li>
<li class="chapter" data-level="26.10" data-path="week-14-lecture.html"><a href="week-14-lecture.html#principal-components-analysis-pca"><i class="fa fa-check"></i><b>26.10</b> Principal components analysis (PCA)</a></li>
<li class="chapter" data-level="26.11" data-path="week-14-lecture.html"><a href="week-14-lecture.html#principal-components-analysis-pca-1"><i class="fa fa-check"></i><b>26.11</b> Principal components analysis (PCA)</a></li>
<li class="chapter" data-level="26.12" data-path="week-14-lecture.html"><a href="week-14-lecture.html#pca-in-r"><i class="fa fa-check"></i><b>26.12</b> PCA in R</a></li>
<li class="chapter" data-level="26.13" data-path="week-14-lecture.html"><a href="week-14-lecture.html#missing-data"><i class="fa fa-check"></i><b>26.13</b> Missing data</a></li>
<li class="chapter" data-level="26.14" data-path="week-14-lecture.html"><a href="week-14-lecture.html#imputing-missing-data"><i class="fa fa-check"></i><b>26.14</b> Imputing missing data</a></li>
</ul></li>
<li class="chapter" data-level="27" data-path="week-14-lab.html"><a href="week-14-lab.html"><i class="fa fa-check"></i><b>27</b> Week 14 Lab</a>
<ul>
<li class="chapter" data-level="27.1" data-path="week-14-lab.html"><a href="week-14-lab.html#missing-at-random---practice-with-glms"><i class="fa fa-check"></i><b>27.1</b> Missing at random - practice with GLMs</a></li>
<li class="chapter" data-level="27.2" data-path="week-14-lab.html"><a href="week-14-lab.html#finally-a-word-about-grades"><i class="fa fa-check"></i><b>27.2</b> Finally, a word about grades</a></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Biometry Lecture and Lab Notes</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="week-10-lab" class="section level1 hasAnchor" number="19">
<h1><span class="header-section-number">19</span> Week 10 Lab<a href="week-10-lab.html#week-10-lab" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<p>There are 7 parts to this week’s lab:</p>
<ol style="list-style-type: decimal">
<li>Discussion of the Challenger analysis</li>
<li>Linear regression with ‘lm’</li>
<li>Weighted linear regression using ‘lm’</li>
<li>Logistic regression</li>
<li>Poisson regression</li>
<li>Understanding deviance</li>
<li>Generalized Additive Models</li>
</ol>
<p>Practice with Multiple regression will be held off until our discussion of model criticism in Week 13.</p>
<div id="discussion-of-challenger-analysis" class="section level2 hasAnchor" number="19.1">
<h2><span class="header-section-number">19.1</span> Discussion of Challenger analysis<a href="week-10-lab.html#discussion-of-challenger-analysis" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>One of the classic datasets for logistic regression is the Challenger dataset, so even though its not related to ecology, I think its worth reading. You have already read the article about the Challenger analysis so you know the background behind the o-ring data. Because the Challenger paper is so well written, we will go over the analysis in detail together.</p>
<p><strong>1-</strong> The night before the launch, there was a meeting to discuss the influence of temperature on o-ring failure. The focus was on Figure 1a showing the number of o-ring failures CONDITIONAL ON there being at least one o-ring failure.</p>
<p><strong>2-</strong> There are 6 o-rings on each shuttle, what is the appropriate model for o-ring failure?</p>
<p><span class="math display">\[
X\sim Binom(n=6,p(t,s))
\]</span></p>
<p>where p(s,t) is the probability of o-ring failure as a function of temperature t and pressure s.</p>
<p><strong>3-</strong> Therefore, the appropriate GLM for o-ring failure is</p>
<p><span class="math display">\[
log\left(\frac{p(t,s)}{1-p(t,s)}\right)=\alpha+\beta t + \gamma s
\]</span></p>
<p><strong>4-</strong> They then fit the model using maximum likelihood (<em>Quick review: What exactly does that mean?</em>)</p>
<p><strong>5-</strong> They calculate the “goodness of fit” statistic <span class="math inline">\(G^{2}\)</span>. This is just another name for the Deviance.</p>
<p><span class="math display">\[
G^{2} = 2*log\left(\frac{\mbox{Likelihood saturated model}}{\mbox{Likelihood model being considered}}\right)
\]</span></p>
<p><span class="math display">\[
\mbox{Deviance} = -2*(\mbox{LL(model being considered)}-\mbox{LL(saturated model)})
\]</span></p>
<p><span class="math display">\[
\mbox{Deviance} = 2*(\mbox{LL(saturated model)}-\mbox{LL(model being considered)})
\]</span></p>
<p><span class="math display">\[
\mbox{Deviance} = 2*log\left(\frac{\mbox{Likelihood saturated model}}{\mbox{Likelihood model being considered}}\right) = G^{2}
\]</span></p>
<p><strong>6-</strong> Recognizing that devaince is only really meaningful relative to another model, they fit the temperature-only model</p>
<p><span class="math display">\[
log\left(\frac{p(t)}{1-p(t)}\right) = \alpha + \beta t
\]</span></p>
<p>The difference in deviances is given by</p>
<p><span class="math display">\[
\mbox{Deviance difference} \sim \chi^{2}_{\mbox{additional parameters}}
\]</span></p>
<p>How many additional parameters in this case?</p>
<p>Just one, so</p>
<p><span class="math display">\[
\mbox{Deviance difference} \sim \chi^{2}_{1}
\]</span></p>
<p>The difference in deviance is not significant, i.e. this model fits about as well as the more complex model, so we can say that pressure has little effect on the probability of o-ring failure and we drop it from the model.</p>
<p><strong>7-</strong> They construct 90th percentile confidence intervals for the expected number of incidents.</p>
<p><strong><span style="color: green;">Checkpoint #1: What exactly are they doing here? Do you understand what they have done and why?</span></strong> <span style="color: white;">They are sampling with replacement from the original data and are refitting the model each time.</span></p>
<p><strong>8-</strong> Next they plot the contours of the log-likelihood function and note that the contours are elliptical and therefore the data were not leading to ill-conditioned computation.</p>
<p><em>What do they mean by that?</em></p>
<p><strong>9-</strong> They collapse the binomial data to make a Bernoulli dataset in which “0” means that no o-rings failed, and “1” means that at least one o-ring failed.</p>
<p><strong><span style="color: green;">Checkpoint #2: Why did they do this?</span></strong>
<span style="color: white;">Because the o-rings may not be independent</span></p>
<p><strong>10-</strong> They refit the data using the Bernoulli model and find that the fits are quite close.</p>
<p><strong>11-</strong> They want to construct confidence intervals for the model parameters. They say “instead of using the aymptotic theory to construct confidence intervals, we use the parametric bootstrap procedure”.</p>
<p><strong><span style="color: green;">Checkpoint #3: Why might they have used a bootstrap approach here?</span></strong></p>
<p><span style="color: white;">Small size size probably…</span></p>
<p><em>How do they do a parametric bootstrap?</em></p>
<p>They take the best-fit model, sample with replacement from the logistic model (presumably drawing (x,predicted y) pairs at random with replacement), and refit the bootstrapped data to get new model parameter estimates.</p>
<p><strong>12-</strong> Then they look at the sensitivity of the model to each of the data points, by pulling out each data point in turn and refitting the model.</p>
<p><strong><span style="color: green;">Checkpoint #4: What is this called?</span></strong></p>
<p><span style="color: white;">Jackknife!</span></p>
<p><strong>13-</strong> They next consider a non-linear model of the form</p>
<p><span class="math display">\[
log\left(\frac{p(t,s)}{1-p(t,s)}\right)=\alpha + \beta(t-t_{0})+\gamma(t-t_{0})^{2}
\]</span></p>
<p><strong>14-</strong> They again consider the change in deviance in going from the simpler linear model to the more complex quadratic model, and they find the quadratic term is not significant.</p>
<p><strong>15-</strong> They then consider a model in which they use a non-parametric smoothing fit (using a moving window appraoch) in Figure 8.</p>
<p><strong>16-</strong> They identify possible outliers in the data (more on model criticism in three weeks).</p>
<p>You should have downloaded the data linking O-ring failure to launch temperature.</p>
<p>Response: Presence/Absence of erosion or blow-by on at least one o-ring field joint (Y=1 if occured, 0 if not)</p>
<p>Predictor Variable: Temperature at lift-off (degrees Fahrenheit)</p>
<p>Sample size: 23 shuttle lift-offs prior to Challenger</p>
<div class="sourceCode" id="cb636"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb636-1"><a href="week-10-lab.html#cb636-1" tabindex="-1"></a>challenger<span class="ot">&lt;-</span><span class="fu">read.csv</span>(<span class="st">&quot;_data/Challenger_data.csv&quot;</span>,<span class="at">head=</span>T)</span>
<span id="cb636-2"><a href="week-10-lab.html#cb636-2" tabindex="-1"></a>challenger</span></code></pre></div>
<pre><code>##    Flight.number Temp O.ring.failure
## 1              1   66              0
## 2              2   70              1
## 3              3   69              0
## 4              4   68              0
## 5              5   67              0
## 6              6   72              0
## 7              7   73              0
## 8              8   70              0
## 9              9   57              1
## 10            10   63              1
## 11            11   70              1
## 12            12   78              0
## 13            13   67              0
## 14            14   53              1
## 15            15   67              0
## 16            16   75              0
## 17            17   70              0
## 18            18   81              0
## 19            19   76              0
## 20            20   79              0
## 21            21   75              1
## 22            22   76              0
## 23            23   58              1</code></pre>
<div class="sourceCode" id="cb638"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb638-1"><a href="week-10-lab.html#cb638-1" tabindex="-1"></a><span class="fu">attach</span>(challenger)</span>
<span id="cb638-2"><a href="week-10-lab.html#cb638-2" tabindex="-1"></a><span class="fu">plot</span>(Temp,O.ring.failure,<span class="at">xlab=</span><span class="st">&quot;Temperature&quot;</span>,<span class="at">ylab=</span><span class="st">&quot;Damage&quot;</span>,<span class="at">main=</span><span class="st">&quot;O-ring damage vs. Temperature&quot;</span>)</span>
<span id="cb638-3"><a href="week-10-lab.html#cb638-3" tabindex="-1"></a>challenger.fit1<span class="ot">&lt;-</span><span class="fu">lm</span>(O.ring.failure<span class="sc">~</span>Temp)</span>
<span id="cb638-4"><a href="week-10-lab.html#cb638-4" tabindex="-1"></a><span class="fu">summary</span>(challenger.fit1)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = O.ring.failure ~ Temp)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -0.43762 -0.30679 -0.06381  0.17452  0.89881 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)   
## (Intercept)  2.90476    0.84208   3.450  0.00240 **
## Temp        -0.03738    0.01205  -3.103  0.00538 **
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 0.3987 on 21 degrees of freedom
## Multiple R-squared:  0.3144, Adjusted R-squared:  0.2818 
## F-statistic:  9.63 on 1 and 21 DF,  p-value: 0.005383</code></pre>
<div class="sourceCode" id="cb640"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb640-1"><a href="week-10-lab.html#cb640-1" tabindex="-1"></a><span class="fu">lines</span>(Temp,<span class="fu">fitted</span>(challenger.fit1),<span class="at">col=</span><span class="st">&quot;red&quot;</span>)</span></code></pre></div>
<p><img src="Week-10-lab_files/figure-html/unnamed-chunk-2-1.png" width="672" /></p>
<p>What’s wrong with this model?<br />
(1) predictions will quickly escape the bounds (0,1)<br />
(2) residuals are clearly not normal</p>
<div class="sourceCode" id="cb641"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb641-1"><a href="week-10-lab.html#cb641-1" tabindex="-1"></a>resid1<span class="ot">&lt;-</span><span class="fu">residuals</span>(challenger.fit1)</span>
<span id="cb641-2"><a href="week-10-lab.html#cb641-2" tabindex="-1"></a><span class="fu">plot</span>(Temp,resid1,<span class="at">xlab=</span><span class="st">&quot;Temperature&quot;</span>,<span class="at">ylab=</span><span class="st">&quot;Residuals for lm model&quot;</span>)</span></code></pre></div>
<p><img src="Week-10-lab_files/figure-html/unnamed-chunk-3-1.png" width="672" /></p>
</div>
<div id="weighted-linear-regression" class="section level2 hasAnchor" number="19.2">
<h2><span class="header-section-number">19.2</span> Weighted linear regression<a href="week-10-lab.html#weighted-linear-regression" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>One possible solution to these problems is to use weighted linear regression (to account for high variance at intermediate temperatures) and to truncate the predicted values to the range (0,1).</p>
<p>Remember that weighted linear regression is just like ordinary linear regression except that we minimize the weighted squared residuals</p>
<p><span class="math display">\[
\mbox{weighted SS} = \sum^{n}_{i=1} w_{i} (Y_{i}-\hat{Y}_{i})^{2}
\]</span></p>
<p>The idea behind weighted linear regression is to give lower weights to observations with high variances so they have less influence over the final model fits. While any weights could be chosen, the inverse variances are most commonly used,</p>
<p><span class="math display">\[
w_{i} = \frac{1}{Variance}
\]</span></p>
<p>which, for Binomially distributed data is given by</p>
<p><span class="math display">\[
w_{i} = \frac{1}{\pi_{i}(1-\pi_{i})}
\]</span></p>
<p>Since the actual probabilities <span class="math inline">\(\pi_{i}\)</span> are unknown, we use estimated weights instead constructed from the empirical proportions as follows:</p>
<p><span class="math display">\[
\hat{w}_{i} = \frac{1}{\hat{Y}_{i}(1-\hat{Y}_{i})}
\]</span></p>
<p>The procedure then goes as follows:</p>
<ol style="list-style-type: decimal">
<li>Fit ordinary least squares<br />
</li>
<li>Obtain estimates <span class="math inline">\(\hat{Y}_{i}\)</span></li>
<li>If an estimate is less than 0 or greater than 1, set it to 0.001 (or something small) and 0.999 (or something close to but less than one), respectively</li>
<li>Compute the weights <span class="math inline">\(W_{i}\)</span></li>
<li>Fit weighted least squares</li>
</ol>
<p>We have the estimates already, they are</p>
<div class="sourceCode" id="cb642"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb642-1"><a href="week-10-lab.html#cb642-1" tabindex="-1"></a><span class="fu">fitted</span>(challenger.fit1)</span></code></pre></div>
<pre><code>##           1           2           3           4           5           6 
##  0.43761905  0.28809524  0.32547619  0.36285714  0.40023810  0.21333333 
##           7           8           9          10          11          12 
##  0.17595238  0.28809524  0.77404762  0.54976190  0.28809524 -0.01095238 
##          13          14          15          16          17          18 
##  0.40023810  0.92357143  0.40023810  0.10119048  0.28809524 -0.12309524 
##          19          20          21          22          23 
##  0.06380952 -0.04833333  0.10119048  0.06380952  0.73666667</code></pre>
<p>We have to truncate these to the correct range but notice that we cannot set any values exactly to 0 or 1 because this would make the estimated variance blow up, so we set <span class="math inline">\(\hat{Y}_{i} &lt; 0\)</span> to 0.001 and <span class="math inline">\(\hat{Y}_{i} &gt; 0\)</span> to 0.999. We can do this in one step by using the ‘pmin’ and ‘pmax’ functions:</p>
<p>Sidenote: Using the ‘pmin’ and ‘pmax’ functions</p>
<div class="sourceCode" id="cb644"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb644-1"><a href="week-10-lab.html#cb644-1" tabindex="-1"></a><span class="fu">pmin</span>(<span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">2</span>,<span class="dv">3</span>),<span class="fu">c</span>(<span class="dv">0</span>,<span class="dv">3</span>,<span class="dv">5</span>))</span></code></pre></div>
<pre><code>## [1] 0 2 3</code></pre>
<div class="sourceCode" id="cb646"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb646-1"><a href="week-10-lab.html#cb646-1" tabindex="-1"></a><span class="fu">pmin</span>(<span class="dv">1</span>,<span class="fu">c</span>(<span class="dv">0</span>,<span class="dv">3</span>,<span class="dv">5</span>))</span></code></pre></div>
<pre><code>## [1] 0 1 1</code></pre>
<p>(The same logic works for ‘pmax’.)</p>
<p>Back to the problem at hand:</p>
<div class="sourceCode" id="cb648"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb648-1"><a href="week-10-lab.html#cb648-1" tabindex="-1"></a>new.predictions<span class="ot">&lt;-</span><span class="fu">pmin</span>(<span class="fl">0.999</span>,<span class="fu">pmax</span>(<span class="fl">0.001</span>,<span class="fu">fitted</span>(challenger.fit1)))</span>
<span id="cb648-2"><a href="week-10-lab.html#cb648-2" tabindex="-1"></a>vars<span class="ot">&lt;-</span>new.predictions<span class="sc">*</span>(<span class="dv">1</span><span class="sc">-</span>new.predictions)</span>
<span id="cb648-3"><a href="week-10-lab.html#cb648-3" tabindex="-1"></a>challenger.fit2<span class="ot">&lt;-</span><span class="fu">lm</span>(O.ring.failure<span class="sc">~</span>Temp,<span class="at">weights=</span>(<span class="dv">1</span><span class="sc">/</span>vars))</span>
<span id="cb648-4"><a href="week-10-lab.html#cb648-4" tabindex="-1"></a><span class="fu">summary</span>(challenger.fit2)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = O.ring.failure ~ Temp, weights = (1/vars))
## 
## Weighted Residuals:
##     Min      1Q  Median      3Q     Max 
## -1.3136 -0.6779 -0.4313  0.8330  2.8846 
## 
## Coefficients:
##              Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)  2.343825   0.532408   4.402 0.000248 ***
## Temp        -0.029517   0.006746  -4.376 0.000265 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 1.105 on 21 degrees of freedom
## Multiple R-squared:  0.4769, Adjusted R-squared:  0.452 
## F-statistic: 19.15 on 1 and 21 DF,  p-value: 0.0002647</code></pre>
<p>Now we can plot the results:</p>
<div class="sourceCode" id="cb650"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb650-1"><a href="week-10-lab.html#cb650-1" tabindex="-1"></a><span class="fu">plot</span>(Temp,O.ring.failure,<span class="at">xlab=</span><span class="st">&quot;Temperature&quot;</span>,<span class="at">ylab=</span><span class="st">&quot;Damage&quot;</span>,<span class="at">main=</span><span class="st">&quot;O-ring Damage vs. Temperature&quot;</span>)</span>
<span id="cb650-2"><a href="week-10-lab.html#cb650-2" tabindex="-1"></a><span class="fu">lines</span>(Temp,<span class="fu">fitted</span>(challenger.fit1),<span class="at">col=</span><span class="st">&quot;red&quot;</span>)</span>
<span id="cb650-3"><a href="week-10-lab.html#cb650-3" tabindex="-1"></a><span class="fu">lines</span>(Temp,<span class="fu">fitted</span>(challenger.fit2),<span class="at">col=</span><span class="st">&quot;blue&quot;</span>)</span></code></pre></div>
<p><img src="Week-10-lab_files/figure-html/unnamed-chunk-7-1.png" width="672" /></p>
<p>The <span class="math inline">\(R^{2}\)</span> of the weighted model is higher, but the fit still has the same problems as the original fit. To properly solve this problem, we need to do logistic regression, which accurately captures the non-linear form of the relationship and the nature of the residuals.</p>
</div>
<div id="logistic-regression-practice" class="section level2 hasAnchor" number="19.3">
<h2><span class="header-section-number">19.3</span> Logistic regression practice<a href="week-10-lab.html#logistic-regression-practice" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<div class="sourceCode" id="cb651"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb651-1"><a href="week-10-lab.html#cb651-1" tabindex="-1"></a>challenger.fit3<span class="ot">&lt;-</span><span class="fu">glm</span>(O.ring.failure<span class="sc">~</span>Temp, <span class="at">family=</span><span class="st">&quot;binomial&quot;</span>)</span>
<span id="cb651-2"><a href="week-10-lab.html#cb651-2" tabindex="-1"></a><span class="fu">plot</span>(Temp,O.ring.failure,<span class="at">xlab=</span><span class="st">&quot;Temperature&quot;</span>,<span class="at">ylab=</span><span class="st">&quot;Damage&quot;</span>,<span class="at">main=</span><span class="st">&quot;O-ring Damage vs. Temperature&quot;</span>) </span>
<span id="cb651-3"><a href="week-10-lab.html#cb651-3" tabindex="-1"></a><span class="co"># Above line only needed because RMarkdown doesn&#39;t keep previous plot</span></span>
<span id="cb651-4"><a href="week-10-lab.html#cb651-4" tabindex="-1"></a><span class="fu">lines</span>(Temp,<span class="fu">fitted</span>(challenger.fit1),<span class="at">col=</span><span class="st">&quot;red&quot;</span>) </span>
<span id="cb651-5"><a href="week-10-lab.html#cb651-5" tabindex="-1"></a><span class="co"># Above line only needed because RMarkdown doesn&#39;t keep previous plot</span></span>
<span id="cb651-6"><a href="week-10-lab.html#cb651-6" tabindex="-1"></a><span class="fu">lines</span>(Temp,<span class="fu">fitted</span>(challenger.fit2),<span class="at">col=</span><span class="st">&quot;blue&quot;</span>) </span>
<span id="cb651-7"><a href="week-10-lab.html#cb651-7" tabindex="-1"></a><span class="co"># Above line only needed because RMarkdown doesn&#39;t keep previous plot</span></span>
<span id="cb651-8"><a href="week-10-lab.html#cb651-8" tabindex="-1"></a><span class="fu">lines</span>(<span class="fu">sort</span>(Temp), <span class="fu">fitted</span>(challenger.fit3)[<span class="fu">order</span>(Temp)],<span class="at">col=</span><span class="st">&quot;green&quot;</span>,<span class="at">lwd=</span><span class="dv">2</span>)</span></code></pre></div>
<p><img src="Week-10-lab_files/figure-html/unnamed-chunk-8-1.png" width="672" /></p>
<div class="sourceCode" id="cb652"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb652-1"><a href="week-10-lab.html#cb652-1" tabindex="-1"></a><span class="fu">summary</span>(challenger.fit3)</span></code></pre></div>
<pre><code>## 
## Call:
## glm(formula = O.ring.failure ~ Temp, family = &quot;binomial&quot;)
## 
## Deviance Residuals: 
##     Min       1Q   Median       3Q      Max  
## -1.0611  -0.7613  -0.3783   0.4524   2.2175  
## 
## Coefficients:
##             Estimate Std. Error z value Pr(&gt;|z|)  
## (Intercept)  15.0429     7.3786   2.039   0.0415 *
## Temp         -0.2322     0.1082  -2.145   0.0320 *
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for binomial family taken to be 1)
## 
##     Null deviance: 28.267  on 22  degrees of freedom
## Residual deviance: 20.315  on 21  degrees of freedom
## AIC: 24.315
## 
## Number of Fisher Scoring iterations: 5</code></pre>
<div class="sourceCode" id="cb654"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb654-1"><a href="week-10-lab.html#cb654-1" tabindex="-1"></a>newdata<span class="ot">&lt;-</span><span class="fu">data.frame</span>(<span class="at">Temp=</span><span class="fu">seq</span>(<span class="dv">30</span>,<span class="dv">85</span>))</span>
<span id="cb654-2"><a href="week-10-lab.html#cb654-2" tabindex="-1"></a>confidence.bands<span class="ot">&lt;-</span><span class="fu">predict.glm</span>(challenger.fit3,newdata,<span class="at">se.fit=</span><span class="cn">TRUE</span>)</span></code></pre></div>
<p><strong>Important note</strong>: If we were modelling data on the number of O-rings failed as a Binomial distribution rather than the existence of failed O-rings as a Bernoulli, we would have to pass the data to glm() in a slightly different way. In particular, we would have to create a two-column object, where the first column is the number of O-rings failed, and the second column is the number of O-rings that did not fail. The glm() call would look something like:</p>
<div class="sourceCode" id="cb655"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb655-1"><a href="week-10-lab.html#cb655-1" tabindex="-1"></a>challenger.fit3<span class="ot">&lt;-</span><span class="fu">glm</span>(<span class="fu">cbind</span>(O.ring.failure, <span class="dv">6</span><span class="sc">-</span>O.ring.failure)<span class="sc">~</span>Temp, <span class="at">family=</span><span class="st">&quot;binomial&quot;</span>)</span></code></pre></div>
<p>OK, back to the task at hand…The default is for predict.glm to give you the fit and s.e. on the scale of the predictor, so you need to use the inverse logit function to extract the fit and s.e. on the scale of the probabilities.</p>
<p>In other words, the model is given by:</p>
<p><span class="math display">\[
Y_{i} \sim \text{Binom}(n_{i},p_{i}) \\
logit(p_{i}) = \beta_{0} + \beta_{1}X_{i}
\]</span>
and R’s function predict.glm() provides the confidence intervals on the right hand side of this latter equation, that is</p>
<p><span class="math display">\[
\text{confidence interval} = [\text{LL of } (\beta_{0} + \beta_{1}X_{i}), \text{UL of } (\beta_{0} + \beta_{1}X_{i})]
\]</span></p>
<p>Therefore, in order to construct confidence intervals on the scale of the probability <span class="math inline">\(p\)</span>, you need to back-transform, so the LL for <span class="math inline">\(p\)</span> is given by <span class="math inline">\(logit^{-1}(\text{LL of } (\beta_{0} + \beta_{1}X_{i}))\)</span> and the UL is given by <span class="math inline">\(logit^{-1}(\text{UL of } (\beta_{0} + \beta_{1}X_{i}))\)</span>. Operationally, this looks as follows in R:</p>
<div class="sourceCode" id="cb656"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb656-1"><a href="week-10-lab.html#cb656-1" tabindex="-1"></a><span class="fu">library</span>(boot)</span>
<span id="cb656-2"><a href="week-10-lab.html#cb656-2" tabindex="-1"></a><span class="fu">plot</span>(Temp,O.ring.failure,<span class="at">xlab=</span><span class="st">&quot;Temperature&quot;</span>,<span class="at">ylab=</span><span class="st">&quot;Damage&quot;</span>,<span class="at">main=</span><span class="st">&quot;O-ring Damage vs. Temperature&quot;</span>) </span>
<span id="cb656-3"><a href="week-10-lab.html#cb656-3" tabindex="-1"></a><span class="co"># Above line only needed because RMarkdown doesn&#39;t keep previous plot</span></span>
<span id="cb656-4"><a href="week-10-lab.html#cb656-4" tabindex="-1"></a><span class="fu">lines</span>(newdata[,<span class="dv">1</span>],<span class="fu">inv.logit</span>(confidence.bands<span class="sc">$</span>fit),<span class="at">col=</span><span class="st">&quot;purple&quot;</span>,<span class="at">lwd=</span><span class="dv">2</span>)</span>
<span id="cb656-5"><a href="week-10-lab.html#cb656-5" tabindex="-1"></a><span class="fu">lines</span>(newdata[,<span class="dv">1</span>],<span class="fu">inv.logit</span>(confidence.bands<span class="sc">$</span>fit<span class="fl">+1.96</span><span class="sc">*</span>confidence.bands<span class="sc">$</span>se.fit),<span class="at">col=</span><span class="st">&quot;purple&quot;</span>,<span class="at">lwd=</span><span class="dv">2</span>,<span class="at">lty=</span><span class="dv">2</span>)</span>
<span id="cb656-6"><a href="week-10-lab.html#cb656-6" tabindex="-1"></a><span class="fu">lines</span>(newdata[,<span class="dv">1</span>],<span class="fu">inv.logit</span>(confidence.bands<span class="sc">$</span>fit<span class="fl">-1.96</span><span class="sc">*</span>confidence.bands<span class="sc">$</span>se.fit),<span class="at">col=</span><span class="st">&quot;purple&quot;</span>,<span class="at">lwd=</span><span class="dv">2</span>,<span class="at">lty=</span><span class="dv">2</span>)</span></code></pre></div>
<p><img src="Week-10-lab_files/figure-html/unnamed-chunk-10-1.png" width="672" /></p>
<p>If you look at the help file for predict.glm, you will see that the only option is a confidence interval on the model (a ‘confidence’ interval). There is no way to generate a prediction interval for GLMs generally speaking. <strong><span style="color: green;">Checkpoint #5: How would you construct a prediction interval for a binary value?</span></strong><span style="color: white;">You cannot, it doesn’t make sense, the value is either 0 or 1.</span></p>
<p>On the day of the Challenger launch, the temperature was 31 degrees - what was the probability of o-ring failure?</p>
<p>[Work this out at home!]</p>
<p>Now we will calculate the deviances reported by summary(), and discuss the AIC (to be discussed more formally next week).</p>
<div class="sourceCode" id="cb657"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb657-1"><a href="week-10-lab.html#cb657-1" tabindex="-1"></a><span class="sc">-</span><span class="dv">2</span><span class="sc">*</span><span class="fu">logLik</span>(challenger.fit3)</span></code></pre></div>
<pre><code>## &#39;log Lik.&#39; 20.31519 (df=2)</code></pre>
<div class="sourceCode" id="cb659"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb659-1"><a href="week-10-lab.html#cb659-1" tabindex="-1"></a>challenger.fit4<span class="ot">&lt;-</span><span class="fu">glm</span>(O.ring.failure<span class="sc">~</span><span class="dv">1</span>,<span class="at">family=</span>binomial)</span>
<span id="cb659-2"><a href="week-10-lab.html#cb659-2" tabindex="-1"></a><span class="sc">-</span><span class="dv">2</span><span class="sc">*</span><span class="fu">logLik</span>(challenger.fit4)</span></code></pre></div>
<pre><code>## &#39;log Lik.&#39; 28.26715 (df=1)</code></pre>
<p>The null deviance is that with only an intercept. The statistical significance of the model can be assessed by comparing the deviance with the parameters vs. the model with only an intercept.</p>
</div>
<div id="poisson-regression-practice" class="section level2 hasAnchor" number="19.4">
<h2><span class="header-section-number">19.4</span> Poisson regression practice<a href="week-10-lab.html#poisson-regression-practice" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Since we have the data loaded already, we will use the challenger o-ring data to illustrate how a Poisson model is fit, even though a Poisson model would be inappropriate for the o-ring data. <strong><span style="color: green;">Checkpoint #6: Why is a Poisson model inappropriate?</span></strong></p>
<p>Note that now the link function is the <span class="math inline">\(log()\)</span> so the inverse link function needed to get a CI of the Poisson intensity <span class="math inline">\(\lambda\)</span> is now the exponential <span class="math inline">\(exp()\)</span>. In other words, to construct confidence intervals on the scale of the intensity <span class="math inline">\(\lambda\)</span>, you need to back-transform, so the LL for <span class="math inline">\(p\)</span> is given by <span class="math inline">\(exp^{\text{LL of } (\beta_{0} + \beta_{1}X_{i})}\)</span> and the UL is given by <span class="math inline">\(exp^{\text{UL of } (\beta_{0} + \beta_{1}X_{i})}\)</span>.</p>
<div class="sourceCode" id="cb661"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb661-1"><a href="week-10-lab.html#cb661-1" tabindex="-1"></a>challenger.fit4<span class="ot">&lt;-</span><span class="fu">glm</span>(O.ring.failure<span class="sc">~</span>Temp,<span class="at">family=</span><span class="st">&quot;poisson&quot;</span>)</span>
<span id="cb661-2"><a href="week-10-lab.html#cb661-2" tabindex="-1"></a><span class="fu">summary</span>(challenger.fit4)</span></code></pre></div>
<pre><code>## 
## Call:
## glm(formula = O.ring.failure ~ Temp, family = &quot;poisson&quot;)
## 
## Deviance Residuals: 
##      Min        1Q    Median        3Q       Max  
## -0.81159  -0.67620  -0.48134  -0.04632   1.53598  
## 
## Coefficients:
##             Estimate Std. Error z value Pr(&gt;|z|)  
## (Intercept)  5.78518    3.13068   1.848   0.0646 .
## Temp        -0.10448    0.04878  -2.142   0.0322 *
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for poisson family taken to be 1)
## 
##     Null deviance: 16.654  on 22  degrees of freedom
## Residual deviance: 12.206  on 21  degrees of freedom
## AIC: 30.206
## 
## Number of Fisher Scoring iterations: 6</code></pre>
<div class="sourceCode" id="cb663"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb663-1"><a href="week-10-lab.html#cb663-1" tabindex="-1"></a>confidence.bands<span class="ot">&lt;-</span><span class="fu">predict.glm</span>(challenger.fit4,newdata,<span class="at">se.fit=</span><span class="cn">TRUE</span>)</span>
<span id="cb663-2"><a href="week-10-lab.html#cb663-2" tabindex="-1"></a><span class="fu">plot</span>(Temp,O.ring.failure,<span class="at">xlab=</span><span class="st">&quot;Temperature&quot;</span>,<span class="at">ylab=</span><span class="st">&quot;Damage&quot;</span>,<span class="at">main=</span><span class="st">&quot;O-ring Damage vs. Temperature&quot;</span>) </span>
<span id="cb663-3"><a href="week-10-lab.html#cb663-3" tabindex="-1"></a><span class="co"># Above line only needed because RMarkdown doesn&#39;t keep previous plot</span></span>
<span id="cb663-4"><a href="week-10-lab.html#cb663-4" tabindex="-1"></a><span class="fu">lines</span>(newdata[,<span class="dv">1</span>],<span class="fu">exp</span>(confidence.bands<span class="sc">$</span>fit),<span class="at">col=</span><span class="st">&quot;orange&quot;</span>,<span class="at">lwd=</span><span class="dv">2</span>)</span>
<span id="cb663-5"><a href="week-10-lab.html#cb663-5" tabindex="-1"></a><span class="fu">lines</span>(newdata[,<span class="dv">1</span>],<span class="fu">exp</span>(confidence.bands<span class="sc">$</span>fit<span class="fl">+1.96</span><span class="sc">*</span>confidence.bands<span class="sc">$</span>se.fit),<span class="at">col=</span><span class="st">&quot;orange&quot;</span>,<span class="at">lwd=</span><span class="dv">2</span>,<span class="at">lty=</span><span class="dv">3</span>)</span>
<span id="cb663-6"><a href="week-10-lab.html#cb663-6" tabindex="-1"></a><span class="fu">lines</span>(newdata[,<span class="dv">1</span>],<span class="fu">exp</span>(confidence.bands<span class="sc">$</span>fit<span class="fl">-1.96</span><span class="sc">*</span>confidence.bands<span class="sc">$</span>se.fit),<span class="at">col=</span><span class="st">&quot;orange&quot;</span>,<span class="at">lwd=</span><span class="dv">2</span>,<span class="at">lty=</span><span class="dv">3</span>)</span></code></pre></div>
<p><img src="Week-10-lab_files/figure-html/unnamed-chunk-12-1.png" width="672" /></p>
<p>We can see that the Poisson model has no inflection point and therefore its predictions would not be bounded by (0,1).</p>
</div>
<div id="getting-a-feel-for-deviance" class="section level2 hasAnchor" number="19.5">
<h2><span class="header-section-number">19.5</span> Getting a feel for Deviance<a href="week-10-lab.html#getting-a-feel-for-deviance" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>We can use the challenger dataset to get a feel for deviance, and the idea that while a larger model will always fit the data better (i.e. have a lower deviance), we need to make sure that the improvement in deviance is more than what would be expected by random chance. This is best illsutrated by an example.</p>
<p>We’re going to look at the null expectation for the deviance difference of two models that differ by a single randomly generated covariate. In other words, we will add a covariate which is <em>just noise</em> and show that the deviance decrease we get adding a random covariate goes as a chi-squared distribution with 1 d.o.f.</p>
<div class="sourceCode" id="cb664"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb664-1"><a href="week-10-lab.html#cb664-1" tabindex="-1"></a><span class="co"># Fit a logistic regression with Temp as the only covariate </span></span>
<span id="cb664-2"><a href="week-10-lab.html#cb664-2" tabindex="-1"></a>challenger.smaller.model <span class="ot">&lt;-</span> <span class="fu">glm</span>(O.ring.failure <span class="sc">~</span> Temp, <span class="at">data=</span>challenger, <span class="at">family=</span><span class="st">&quot;binomial&quot;</span>)</span>
<span id="cb664-3"><a href="week-10-lab.html#cb664-3" tabindex="-1"></a><span class="co"># Generate a random covariate with same mean and sd as Temp</span></span>
<span id="cb664-4"><a href="week-10-lab.html#cb664-4" tabindex="-1"></a>randvar <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(<span class="at">n=</span><span class="fu">length</span>(challenger<span class="sc">$</span>Temp), <span class="at">mean=</span><span class="fu">mean</span>(challenger<span class="sc">$</span>Temp), <span class="at">sd=</span><span class="fu">sd</span>(challenger<span class="sc">$</span>Temp))</span>
<span id="cb664-5"><a href="week-10-lab.html#cb664-5" tabindex="-1"></a><span class="co"># Add the random covariate to a data frame for model-fitting </span></span>
<span id="cb664-6"><a href="week-10-lab.html#cb664-6" tabindex="-1"></a>newdata <span class="ot">&lt;-</span> <span class="fu">cbind</span>(challenger, randvar)</span>
<span id="cb664-7"><a href="week-10-lab.html#cb664-7" tabindex="-1"></a><span class="co"># Fit the logistic regression with Temp and the random covariate </span></span>
<span id="cb664-8"><a href="week-10-lab.html#cb664-8" tabindex="-1"></a>challenger.larger.model <span class="ot">&lt;-</span> <span class="fu">glm</span>(O.ring.failure <span class="sc">~</span> Temp <span class="sc">+</span> randvar, <span class="at">data=</span>newdata, <span class="at">family=</span><span class="st">&quot;binomial&quot;</span>)</span>
<span id="cb664-9"><a href="week-10-lab.html#cb664-9" tabindex="-1"></a><span class="co"># Calculate the deviance difference of the two models </span></span>
<span id="cb664-10"><a href="week-10-lab.html#cb664-10" tabindex="-1"></a>dev_diff <span class="ot">&lt;-</span> <span class="fu">deviance</span>(challenger.smaller.model) <span class="sc">-</span> <span class="fu">deviance</span>(challenger.larger.model)</span>
<span id="cb664-11"><a href="week-10-lab.html#cb664-11" tabindex="-1"></a>dev_diff</span></code></pre></div>
<pre><code>## [1] 0.5278955</code></pre>
<p>Notice that even though the covariate that we added is just noise, it still decreases the deviance.</p>
<p>Now we need to repeat those steps a number of times to generate a distribution of expected deviance differences</p>
<div class="sourceCode" id="cb666"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb666-1"><a href="week-10-lab.html#cb666-1" tabindex="-1"></a>dev_diff <span class="ot">&lt;-</span> <span class="fu">c</span>()</span>
<span id="cb666-2"><a href="week-10-lab.html#cb666-2" tabindex="-1"></a></span>
<span id="cb666-3"><a href="week-10-lab.html#cb666-3" tabindex="-1"></a><span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">1000</span>){</span>
<span id="cb666-4"><a href="week-10-lab.html#cb666-4" tabindex="-1"></a>  <span class="co"># Generate a random covariate with same mean and sd as Temp</span></span>
<span id="cb666-5"><a href="week-10-lab.html#cb666-5" tabindex="-1"></a>  randvar <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(<span class="at">n=</span><span class="fu">length</span>(challenger<span class="sc">$</span>Temp), <span class="at">mean=</span><span class="fu">mean</span>(challenger<span class="sc">$</span>Temp), <span class="at">sd=</span><span class="fu">sd</span>(challenger<span class="sc">$</span>Temp))</span>
<span id="cb666-6"><a href="week-10-lab.html#cb666-6" tabindex="-1"></a>  </span>
<span id="cb666-7"><a href="week-10-lab.html#cb666-7" tabindex="-1"></a>  <span class="co"># Add the random covariate to a data frame for model-fitting </span></span>
<span id="cb666-8"><a href="week-10-lab.html#cb666-8" tabindex="-1"></a>  newdata <span class="ot">&lt;-</span> <span class="fu">cbind</span>(challenger, randvar)</span>
<span id="cb666-9"><a href="week-10-lab.html#cb666-9" tabindex="-1"></a>  </span>
<span id="cb666-10"><a href="week-10-lab.html#cb666-10" tabindex="-1"></a>  <span class="co"># Fit the model</span></span>
<span id="cb666-11"><a href="week-10-lab.html#cb666-11" tabindex="-1"></a>  challenger.fit.larger.model <span class="ot">&lt;-</span> <span class="fu">glm</span>(O.ring.failure <span class="sc">~</span> Temp <span class="sc">+</span> randvar, <span class="at">data=</span>newdata, <span class="at">family=</span><span class="st">&quot;binomial&quot;</span>)</span>
<span id="cb666-12"><a href="week-10-lab.html#cb666-12" tabindex="-1"></a></span>
<span id="cb666-13"><a href="week-10-lab.html#cb666-13" tabindex="-1"></a>  <span class="co"># Calculate the deviance difference </span></span>
<span id="cb666-14"><a href="week-10-lab.html#cb666-14" tabindex="-1"></a>  dev_diff_rand <span class="ot">&lt;-</span> <span class="fu">deviance</span>(challenger.smaller.model) <span class="sc">-</span> <span class="fu">deviance</span>(challenger.fit.larger.model)</span>
<span id="cb666-15"><a href="week-10-lab.html#cb666-15" tabindex="-1"></a>  </span>
<span id="cb666-16"><a href="week-10-lab.html#cb666-16" tabindex="-1"></a>  dev_diff <span class="ot">&lt;-</span> <span class="fu">c</span>(dev_diff, dev_diff_rand)</span>
<span id="cb666-17"><a href="week-10-lab.html#cb666-17" tabindex="-1"></a>}</span></code></pre></div>
<pre><code>## Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred

## Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred</code></pre>
<div class="sourceCode" id="cb668"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb668-1"><a href="week-10-lab.html#cb668-1" tabindex="-1"></a><span class="co"># plot the distribution and add a line for a chi-square with df=1 </span></span>
<span id="cb668-2"><a href="week-10-lab.html#cb668-2" tabindex="-1"></a><span class="fu">hist</span>(dev_diff, <span class="at">xlab=</span><span class="st">&quot;Deviance Difference&quot;</span>, <span class="at">main=</span><span class="st">&quot;Expected distribution&quot;</span>, <span class="at">freq=</span><span class="cn">FALSE</span>,<span class="at">breaks=</span><span class="dv">30</span>)</span>
<span id="cb668-3"><a href="week-10-lab.html#cb668-3" tabindex="-1"></a><span class="fu">lines</span>(<span class="fu">seq</span>(<span class="dv">0</span>,<span class="dv">20</span>,<span class="fl">0.1</span>), <span class="fu">dchisq</span>(<span class="fu">seq</span>(<span class="dv">0</span>,<span class="dv">20</span>,<span class="fl">0.1</span>),<span class="at">df=</span><span class="dv">1</span>), <span class="at">col=</span><span class="st">&quot;red&quot;</span>,<span class="at">lwd=</span><span class="dv">2</span>)</span></code></pre></div>
<p><img src="Week-10-lab_files/figure-html/unnamed-chunk-14-1.png" width="672" /></p>
<p>Sure enough, as expected, the difference in deviance we get by adding a covariate that has <em>no</em> association with the response is a <span class="math inline">\(\chi^{2}_{1}\)</span> distributed variable. Therefore, to justify adding a covariate to a model, we want to see that the decrease in deviance is much larger than this. Specifically, we want to see that the decrease in deviance is so unlikely to have arisen from a <span class="math inline">\(\chi^{2}_{1}\)</span> distribution that we reject the null hypothesis that the two models are equivalent. (In other words, by rejecting the null hypothesis, we say that the larger model is, in fact, the better model and the additional covariate is worth keeping.)</p>
<p><strong><span style="color: green;">Checkpoint #7: Does this make sense?</span></strong></p>
</div>
<div id="generalized-additive-models" class="section level2 hasAnchor" number="19.6">
<h2><span class="header-section-number">19.6</span> Generalized Additive Models<a href="week-10-lab.html#generalized-additive-models" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>There are two libraries that can fit GAMs: ‘gam’ and ‘mcgv’. We will use the ‘gam’ package for now, but keep in mind that the ‘mgcv’ package is more flexible and more powerful (so worth considering if you need to do GAMs for your own research).</p>
<p>Stop: Install the GAM package and then load it into the workspace using</p>
<div class="sourceCode" id="cb669"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb669-1"><a href="week-10-lab.html#cb669-1" tabindex="-1"></a><span class="fu">library</span>(<span class="st">&#39;gam&#39;</span>)</span></code></pre></div>
<p>Inside the ‘gam’ package is a dataset that we will use on ozone in New York as a function of solar radiation, temperature, and wind.</p>
<p>First we histogram the ozone data</p>
<div class="sourceCode" id="cb670"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb670-1"><a href="week-10-lab.html#cb670-1" tabindex="-1"></a><span class="fu">hist</span>(airquality<span class="sc">$</span>Ozone)</span></code></pre></div>
<p><img src="Week-10-lab_files/figure-html/unnamed-chunk-16-1.png" width="672" /></p>
<p>Clearly the ozone data are not normal. It turns out the log transformation gets the ozone data to something more ‘normal-like’. (How would we compare different transformations of the data? Try and do a ks.test comparing various transformed datasets against the normal.)</p>
<p>First we’ll just fit a linear model for comparison.</p>
<div class="sourceCode" id="cb671"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb671-1"><a href="week-10-lab.html#cb671-1" tabindex="-1"></a>air.lm<span class="ot">&lt;-</span><span class="fu">lm</span>(<span class="fu">log</span>(Ozone)<span class="sc">~</span>Solar.R<span class="sc">+</span>Wind<span class="sc">+</span>Temp,<span class="at">data=</span>airquality)</span>
<span id="cb671-2"><a href="week-10-lab.html#cb671-2" tabindex="-1"></a><span class="fu">summary</span>(air.lm)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = log(Ozone) ~ Solar.R + Wind + Temp, data = airquality)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -2.06193 -0.29970 -0.00231  0.30756  1.23578 
## 
## Coefficients:
##               Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept) -0.2621323  0.5535669  -0.474 0.636798    
## Solar.R      0.0025152  0.0005567   4.518 1.62e-05 ***
## Wind        -0.0615625  0.0157130  -3.918 0.000158 ***
## Temp         0.0491711  0.0060875   8.077 1.07e-12 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 0.5086 on 107 degrees of freedom
##   (42 observations deleted due to missingness)
## Multiple R-squared:  0.6644, Adjusted R-squared:  0.655 
## F-statistic: 70.62 on 3 and 107 DF,  p-value: &lt; 2.2e-16</code></pre>
<p>Now we’ll try fitting this data with a GAM. Note the syntax: s() fits a smoothing spline, lo() would fit a LOESS curve.</p>
<div class="sourceCode" id="cb673"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb673-1"><a href="week-10-lab.html#cb673-1" tabindex="-1"></a>air.gam<span class="ot">&lt;-</span><span class="fu">gam</span>(<span class="fu">log</span>(Ozone)<span class="sc">~</span><span class="fu">s</span>(Solar.R)<span class="sc">+</span><span class="fu">s</span>(Wind)<span class="sc">+</span><span class="fu">s</span>(Temp),<span class="at">data=</span>airquality)</span>
<span id="cb673-2"><a href="week-10-lab.html#cb673-2" tabindex="-1"></a><span class="fu">summary</span>(air.gam)</span></code></pre></div>
<pre><code>## 
## Call: gam(formula = log(Ozone) ~ s(Solar.R) + s(Wind) + s(Temp), data = airquality)
## Deviance Residuals:
##      Min       1Q   Median       3Q      Max 
## -1.84583 -0.24538 -0.04403  0.31419  0.99890 
## 
## (Dispersion Parameter for gaussian family taken to be 0.2235)
## 
##     Null Deviance: 82.47 on 110 degrees of freedom
## Residual Deviance: 21.9077 on 98.0001 degrees of freedom
## AIC: 162.8854 
## 42 observations deleted due to missingness 
## 
## Number of Local Scoring Iterations: NA 
## 
## Anova for Parametric Effects
##            Df Sum Sq Mean Sq F value    Pr(&gt;F)    
## s(Solar.R)  1 16.041 16.0408  71.756 2.484e-13 ***
## s(Wind)     1 17.208 17.2083  76.978 5.521e-14 ***
## s(Temp)     1 12.723 12.7227  56.913 2.351e-11 ***
## Residuals  98 21.908  0.2235                      
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Anova for Nonparametric Effects
##             Npar Df Npar F   Pr(F)  
## (Intercept)                         
## s(Solar.R)        3 2.8465 0.04151 *
## s(Wind)           3 3.4736 0.01897 *
## s(Temp)           3 2.9358 0.03713 *
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<div class="sourceCode" id="cb675"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb675-1"><a href="week-10-lab.html#cb675-1" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow=</span><span class="fu">c</span>(<span class="dv">3</span>,<span class="dv">1</span>))</span>
<span id="cb675-2"><a href="week-10-lab.html#cb675-2" tabindex="-1"></a><span class="fu">plot</span>(air.gam,<span class="at">se=</span>T)</span></code></pre></div>
<p><img src="Week-10-lab_files/figure-html/unnamed-chunk-18-1.png" width="672" /></p>
<p>The default is that the smoothing splines have df=4, but we can control the amount of smoothing by changing the number of d.o.f.</p>
<div class="sourceCode" id="cb676"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb676-1"><a href="week-10-lab.html#cb676-1" tabindex="-1"></a>air.gam<span class="ot">&lt;-</span><span class="fu">gam</span>(<span class="fu">log</span>(Ozone)<span class="sc">~</span><span class="fu">s</span>(Solar.R,<span class="at">df=</span><span class="dv">20</span>)<span class="sc">+</span><span class="fu">s</span>(Wind)<span class="sc">+</span><span class="fu">s</span>(Temp),<span class="at">data=</span>airquality)</span>
<span id="cb676-2"><a href="week-10-lab.html#cb676-2" tabindex="-1"></a><span class="fu">plot</span>(air.gam,<span class="at">se=</span>T)</span></code></pre></div>
<p><img src="Week-10-lab_files/figure-html/unnamed-chunk-19-1.png" width="672" /><img src="Week-10-lab_files/figure-html/unnamed-chunk-19-2.png" width="672" /><img src="Week-10-lab_files/figure-html/unnamed-chunk-19-3.png" width="672" /></p>
<p>That makes the curve for Solar.R much more curvy.</p>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="week-10-lecture.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="week-11-lecture.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": null,
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
