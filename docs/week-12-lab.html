<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>23 Week 12 Lab | Biometry Lecture and Lab Notes</title>
  <meta name="description" content="23 Week 12 Lab | Biometry Lecture and Lab Notes" />
  <meta name="generator" content="bookdown 0.37 and GitBook 2.6.7" />

  <meta property="og:title" content="23 Week 12 Lab | Biometry Lecture and Lab Notes" />
  <meta property="og:type" content="book" />
  
  
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="23 Week 12 Lab | Biometry Lecture and Lab Notes" />
  
  
  

<meta name="author" content="Heather Lynch" />


<meta name="date" content="2024-04-30" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="week-12-lecture.html"/>
<link rel="next" href="week-13-lecture.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>
<script src="libs/kePrint-0.0.1/kePrint.js"></script>
<link href="libs/lightable-0.0.1/lightable.css" rel="stylesheet" />


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
  
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Biometry Lecture and Lab Notes</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface, data sets, and past exams</a></li>
<li class="chapter" data-level="1" data-path="week-1-lecture.html"><a href="week-1-lecture.html"><i class="fa fa-check"></i><b>1</b> Week 1 Lecture</a>
<ul>
<li class="chapter" data-level="1.1" data-path="week-1-lecture.html"><a href="week-1-lecture.html#week-1-readings"><i class="fa fa-check"></i><b>1.1</b> Week 1 Readings</a></li>
<li class="chapter" data-level="1.2" data-path="week-1-lecture.html"><a href="week-1-lecture.html#basic-outline"><i class="fa fa-check"></i><b>1.2</b> Basic Outline</a></li>
<li class="chapter" data-level="1.3" data-path="week-1-lecture.html"><a href="week-1-lecture.html#todays-agenda"><i class="fa fa-check"></i><b>1.3</b> Today’s Agenda</a></li>
<li class="chapter" data-level="1.4" data-path="week-1-lecture.html"><a href="week-1-lecture.html#basic-probability-theory"><i class="fa fa-check"></i><b>1.4</b> Basic Probability Theory</a>
<ul>
<li class="chapter" data-level="1.4.1" data-path="week-1-lecture.html"><a href="week-1-lecture.html#intersection"><i class="fa fa-check"></i><b>1.4.1</b> Intersection</a></li>
<li class="chapter" data-level="1.4.2" data-path="week-1-lecture.html"><a href="week-1-lecture.html#union"><i class="fa fa-check"></i><b>1.4.2</b> Union</a></li>
</ul></li>
<li class="chapter" data-level="1.5" data-path="week-1-lecture.html"><a href="week-1-lecture.html#multiple-events"><i class="fa fa-check"></i><b>1.5</b> Multiple events</a></li>
<li class="chapter" data-level="1.6" data-path="week-1-lecture.html"><a href="week-1-lecture.html#conditionals"><i class="fa fa-check"></i><b>1.6</b> Conditionals</a></li>
<li class="chapter" data-level="1.7" data-path="week-1-lecture.html"><a href="week-1-lecture.html#a-few-foundational-ideas"><i class="fa fa-check"></i><b>1.7</b> A few foundational ideas</a></li>
<li class="chapter" data-level="1.8" data-path="week-1-lecture.html"><a href="week-1-lecture.html#degrees-of-freedom"><i class="fa fa-check"></i><b>1.8</b> Degrees of freedom</a></li>
<li class="chapter" data-level="1.9" data-path="week-1-lecture.html"><a href="week-1-lecture.html#quick-intro-to-the-gaussian-distribution"><i class="fa fa-check"></i><b>1.9</b> Quick intro to the Gaussian distribution</a></li>
<li class="chapter" data-level="1.10" data-path="week-1-lecture.html"><a href="week-1-lecture.html#overview-of-univariate-distributions"><i class="fa fa-check"></i><b>1.10</b> Overview of Univariate Distributions</a></li>
<li class="chapter" data-level="1.11" data-path="week-1-lecture.html"><a href="week-1-lecture.html#what-can-you-ask-of-a-distribution"><i class="fa fa-check"></i><b>1.11</b> What can you ask of a distribution?</a>
<ul>
<li class="chapter" data-level="1.11.1" data-path="week-1-lecture.html"><a href="week-1-lecture.html#expected-value-of-a-random-variable"><i class="fa fa-check"></i><b>1.11.1</b> Expected Value of a Random Variable</a></li>
<li class="chapter" data-level="1.11.2" data-path="week-1-lecture.html"><a href="week-1-lecture.html#discrete-case"><i class="fa fa-check"></i><b>1.11.2</b> Discrete Case</a></li>
<li class="chapter" data-level="1.11.3" data-path="week-1-lecture.html"><a href="week-1-lecture.html#continuous-case"><i class="fa fa-check"></i><b>1.11.3</b> Continuous Case</a></li>
</ul></li>
<li class="chapter" data-level="1.12" data-path="week-1-lecture.html"><a href="week-1-lecture.html#a-brief-introduction-to-inference-logic-and-reasoning"><i class="fa fa-check"></i><b>1.12</b> A brief introduction to inference, logic, and reasoning</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="week-1-lab.html"><a href="week-1-lab.html"><i class="fa fa-check"></i><b>2</b> Week 1 Lab</a>
<ul>
<li class="chapter" data-level="2.1" data-path="week-1-lab.html"><a href="week-1-lab.html#using-r-like-a-calculator"><i class="fa fa-check"></i><b>2.1</b> Using R like a calculator</a></li>
<li class="chapter" data-level="2.2" data-path="week-1-lab.html"><a href="week-1-lab.html#the-basic-data-structures-in-r"><i class="fa fa-check"></i><b>2.2</b> The basic data structures in R</a></li>
<li class="chapter" data-level="2.3" data-path="week-1-lab.html"><a href="week-1-lab.html#writing-functions-in-r"><i class="fa fa-check"></i><b>2.3</b> Writing functions in R</a></li>
<li class="chapter" data-level="2.4" data-path="week-1-lab.html"><a href="week-1-lab.html#writing-loops-and-ifelse"><i class="fa fa-check"></i><b>2.4</b> Writing loops and if/else</a></li>
<li class="chapter" data-level="2.5" data-path="week-1-lab.html"><a href="week-1-lab.html#pop_vs_sample_var"><i class="fa fa-check"></i><b>2.5</b> (A short diversion) Bias in estimators</a></li>
<li class="chapter" data-level="2.6" data-path="week-1-lab.html"><a href="week-1-lab.html#some-practice-writing-r-code"><i class="fa fa-check"></i><b>2.6</b> Some practice writing R code</a></li>
<li class="chapter" data-level="2.7" data-path="week-1-lab.html"><a href="week-1-lab.html#a-few-final-notes"><i class="fa fa-check"></i><b>2.7</b> A few final notes</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="week-2-lecture.html"><a href="week-2-lecture.html"><i class="fa fa-check"></i><b>3</b> Week 2 Lecture</a>
<ul>
<li class="chapter" data-level="3.1" data-path="week-2-lecture.html"><a href="week-2-lecture.html#week-2-readings"><i class="fa fa-check"></i><b>3.1</b> Week 2 Readings</a></li>
<li class="chapter" data-level="3.2" data-path="week-2-lecture.html"><a href="week-2-lecture.html#todays-agenda-1"><i class="fa fa-check"></i><b>3.2</b> Today’s Agenda</a></li>
<li class="chapter" data-level="3.3" data-path="week-2-lecture.html"><a href="week-2-lecture.html#hypothesis-testing"><i class="fa fa-check"></i><b>3.3</b> Hypothesis testing</a></li>
<li class="chapter" data-level="3.4" data-path="week-2-lecture.html"><a href="week-2-lecture.html#permutation-tests"><i class="fa fa-check"></i><b>3.4</b> Permutation tests</a></li>
<li class="chapter" data-level="3.5" data-path="week-2-lecture.html"><a href="week-2-lecture.html#parameter-estimation"><i class="fa fa-check"></i><b>3.5</b> Parameter estimation</a></li>
<li class="chapter" data-level="3.6" data-path="week-2-lecture.html"><a href="week-2-lecture.html#method-1-non-parametric-bootstrap"><i class="fa fa-check"></i><b>3.6</b> Method #1: Non-parametric bootstrap</a></li>
<li class="chapter" data-level="3.7" data-path="week-2-lecture.html"><a href="week-2-lecture.html#parametric-bootstrap"><i class="fa fa-check"></i><b>3.7</b> Parametric bootstrap</a></li>
<li class="chapter" data-level="3.8" data-path="week-2-lecture.html"><a href="week-2-lecture.html#jackknife"><i class="fa fa-check"></i><b>3.8</b> Jackknife</a></li>
<li class="chapter" data-level="3.9" data-path="week-2-lecture.html"><a href="week-2-lecture.html#jackknife-after-bootstrap"><i class="fa fa-check"></i><b>3.9</b> Jackknife-after-bootstrap</a></li>
<li class="chapter" data-level="3.10" data-path="week-2-lecture.html"><a href="week-2-lecture.html#by-the-end-of-week-2-you-should-understand"><i class="fa fa-check"></i><b>3.10</b> By the end of Week 2, you should understand…</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="week-2-lab.html"><a href="week-2-lab.html"><i class="fa fa-check"></i><b>4</b> Week 2 Lab</a>
<ul>
<li class="chapter" data-level="4.1" data-path="week-2-lab.html"><a href="week-2-lab.html#confidence-intervals"><i class="fa fa-check"></i><b>4.1</b> Confidence intervals</a></li>
<li class="chapter" data-level="4.2" data-path="week-2-lab.html"><a href="week-2-lab.html#testing-hypotheses-through-permutation"><i class="fa fa-check"></i><b>4.2</b> Testing hypotheses through permutation</a></li>
<li class="chapter" data-level="4.3" data-path="week-2-lab.html"><a href="week-2-lab.html#basics-of-bootstrap-and-jackknife"><i class="fa fa-check"></i><b>4.3</b> Basics of bootstrap and jackknife</a></li>
<li class="chapter" data-level="4.4" data-path="week-2-lab.html"><a href="week-2-lab.html#calculating-bias-and-standard-error"><i class="fa fa-check"></i><b>4.4</b> Calculating bias and standard error</a></li>
<li class="chapter" data-level="4.5" data-path="week-2-lab.html"><a href="week-2-lab.html#parametric-bootstrap-1"><i class="fa fa-check"></i><b>4.5</b> Parametric bootstrap</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="week-3-lecture.html"><a href="week-3-lecture.html"><i class="fa fa-check"></i><b>5</b> Week 3 Lecture</a>
<ul>
<li class="chapter" data-level="5.1" data-path="week-3-lecture.html"><a href="week-3-lecture.html#week-3-readings"><i class="fa fa-check"></i><b>5.1</b> Week 3 Readings</a></li>
<li class="chapter" data-level="5.2" data-path="week-3-lecture.html"><a href="week-3-lecture.html#overview-of-probability-distributions"><i class="fa fa-check"></i><b>5.2</b> Overview of probability distributions</a></li>
<li class="chapter" data-level="5.3" data-path="week-3-lecture.html"><a href="week-3-lecture.html#normal-gaussian-distribution"><i class="fa fa-check"></i><b>5.3</b> Normal (Gaussian) Distribution</a></li>
<li class="chapter" data-level="5.4" data-path="week-3-lecture.html"><a href="week-3-lecture.html#standard-normal-distribution"><i class="fa fa-check"></i><b>5.4</b> Standard Normal Distribution</a></li>
<li class="chapter" data-level="5.5" data-path="week-3-lecture.html"><a href="week-3-lecture.html#log-normal-distribution"><i class="fa fa-check"></i><b>5.5</b> Log-Normal Distribution</a></li>
<li class="chapter" data-level="5.6" data-path="week-3-lecture.html"><a href="week-3-lecture.html#intermission-central-limit-theorem"><i class="fa fa-check"></i><b>5.6</b> Intermission: Central Limit Theorem</a></li>
<li class="chapter" data-level="5.7" data-path="week-3-lecture.html"><a href="week-3-lecture.html#poisson-distribution"><i class="fa fa-check"></i><b>5.7</b> Poisson Distribution</a></li>
<li class="chapter" data-level="5.8" data-path="week-3-lecture.html"><a href="week-3-lecture.html#binomial-distribution"><i class="fa fa-check"></i><b>5.8</b> Binomial Distribution</a></li>
<li class="chapter" data-level="5.9" data-path="week-3-lecture.html"><a href="week-3-lecture.html#beta-distribution"><i class="fa fa-check"></i><b>5.9</b> Beta Distribution</a></li>
<li class="chapter" data-level="5.10" data-path="week-3-lecture.html"><a href="week-3-lecture.html#gamma-distribution"><i class="fa fa-check"></i><b>5.10</b> Gamma Distribution</a></li>
<li class="chapter" data-level="5.11" data-path="week-3-lecture.html"><a href="week-3-lecture.html#some-additional-notes"><i class="fa fa-check"></i><b>5.11</b> Some additional notes:</a></li>
<li class="chapter" data-level="5.12" data-path="week-3-lecture.html"><a href="week-3-lecture.html#by-the-end-of-week-3-you-should-understand"><i class="fa fa-check"></i><b>5.12</b> By the end of Week 3, you should understand…</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="week-3-lab.html"><a href="week-3-lab.html"><i class="fa fa-check"></i><b>6</b> Week 3 Lab</a>
<ul>
<li class="chapter" data-level="6.1" data-path="week-3-lab.html"><a href="week-3-lab.html#exploring-the-univariate-distributions-with-r"><i class="fa fa-check"></i><b>6.1</b> Exploring the univariate distributions with R</a></li>
<li class="chapter" data-level="6.2" data-path="week-3-lab.html"><a href="week-3-lab.html#standard-deviation-vs.-standard-error"><i class="fa fa-check"></i><b>6.2</b> Standard deviation vs. Standard error</a></li>
<li class="chapter" data-level="6.3" data-path="week-3-lab.html"><a href="week-3-lab.html#the-central-limit-theorem"><i class="fa fa-check"></i><b>6.3</b> The Central Limit Theorem</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="week-4-lecture.html"><a href="week-4-lecture.html"><i class="fa fa-check"></i><b>7</b> Week 4 Lecture</a>
<ul>
<li class="chapter" data-level="7.1" data-path="week-4-lecture.html"><a href="week-4-lecture.html#week-4-readings"><i class="fa fa-check"></i><b>7.1</b> Week 4 Readings</a></li>
<li class="chapter" data-level="7.2" data-path="week-4-lecture.html"><a href="week-4-lecture.html#t-distribution"><i class="fa fa-check"></i><b>7.2</b> t-distribution</a></li>
<li class="chapter" data-level="7.3" data-path="week-4-lecture.html"><a href="week-4-lecture.html#chi-squared-distribution"><i class="fa fa-check"></i><b>7.3</b> Chi-squared distribution</a></li>
<li class="chapter" data-level="7.4" data-path="week-4-lecture.html"><a href="week-4-lecture.html#f-distribution"><i class="fa fa-check"></i><b>7.4</b> F distribution</a></li>
<li class="chapter" data-level="7.5" data-path="week-4-lecture.html"><a href="week-4-lecture.html#estimating-confidence-intervals---5-special-cases"><i class="fa fa-check"></i><b>7.5</b> Estimating confidence intervals - 5 special cases</a></li>
<li class="chapter" data-level="7.6" data-path="week-4-lecture.html"><a href="week-4-lecture.html#to-recap"><i class="fa fa-check"></i><b>7.6</b> To recap</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="week-4-lab.html"><a href="week-4-lab.html"><i class="fa fa-check"></i><b>8</b> Week 4 Lab</a></li>
<li class="chapter" data-level="9" data-path="week-5-lecture.html"><a href="week-5-lecture.html"><i class="fa fa-check"></i><b>9</b> Week 5 Lecture</a>
<ul>
<li class="chapter" data-level="9.1" data-path="week-5-lecture.html"><a href="week-5-lecture.html#week-5-readings"><i class="fa fa-check"></i><b>9.1</b> Week 5 Readings</a></li>
<li class="chapter" data-level="9.2" data-path="week-5-lecture.html"><a href="week-5-lecture.html#statistical-power"><i class="fa fa-check"></i><b>9.2</b> Statistical power</a></li>
<li class="chapter" data-level="9.3" data-path="week-5-lecture.html"><a href="week-5-lecture.html#the-single-sample-t-test"><i class="fa fa-check"></i><b>9.3</b> The single sample t test</a></li>
<li class="chapter" data-level="9.4" data-path="week-5-lecture.html"><a href="week-5-lecture.html#the-unpaired-two-sample-t-test"><i class="fa fa-check"></i><b>9.4</b> The unpaired two sample t test</a></li>
<li class="chapter" data-level="9.5" data-path="week-5-lecture.html"><a href="week-5-lecture.html#pooledvar"><i class="fa fa-check"></i><b>9.5</b> Pooling the variances</a></li>
<li class="chapter" data-level="9.6" data-path="week-5-lecture.html"><a href="week-5-lecture.html#the-paired-two-sample-t-test"><i class="fa fa-check"></i><b>9.6</b> The paired two sample t test</a></li>
<li class="chapter" data-level="9.7" data-path="week-5-lecture.html"><a href="week-5-lecture.html#the-f-test"><i class="fa fa-check"></i><b>9.7</b> The F test</a></li>
<li class="chapter" data-level="9.8" data-path="week-5-lecture.html"><a href="week-5-lecture.html#comparing-two-proportions"><i class="fa fa-check"></i><b>9.8</b> Comparing two proportions</a></li>
<li class="chapter" data-level="9.9" data-path="week-5-lecture.html"><a href="week-5-lecture.html#comparing-two-distributions"><i class="fa fa-check"></i><b>9.9</b> Comparing two distributions</a></li>
<li class="chapter" data-level="9.10" data-path="week-5-lecture.html"><a href="week-5-lecture.html#a-bit-more-detail-on-the-binomial"><i class="fa fa-check"></i><b>9.10</b> A bit more detail on the Binomial</a></li>
<li class="chapter" data-level="9.11" data-path="week-5-lecture.html"><a href="week-5-lecture.html#side-note-about-the-wald-test"><i class="fa fa-check"></i><b>9.11</b> Side-note about the Wald test</a></li>
<li class="chapter" data-level="9.12" data-path="week-5-lecture.html"><a href="week-5-lecture.html#chi-squared-goodness-of-fit-test"><i class="fa fa-check"></i><b>9.12</b> Chi-squared goodness-of-fit test</a></li>
<li class="chapter" data-level="9.13" data-path="week-5-lecture.html"><a href="week-5-lecture.html#chi-squared-test-of-independence"><i class="fa fa-check"></i><b>9.13</b> Chi-squared test of independence</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="week-5-lab.html"><a href="week-5-lab.html"><i class="fa fa-check"></i><b>10</b> Week 5 Lab</a>
<ul>
<li class="chapter" data-level="10.1" data-path="week-5-lab.html"><a href="week-5-lab.html#t-test"><i class="fa fa-check"></i><b>10.1</b> t-test</a></li>
<li class="chapter" data-level="10.2" data-path="week-5-lab.html"><a href="week-5-lab.html#f-test"><i class="fa fa-check"></i><b>10.2</b> F-test</a></li>
<li class="chapter" data-level="10.3" data-path="week-5-lab.html"><a href="week-5-lab.html#comparing-two-proportions-1"><i class="fa fa-check"></i><b>10.3</b> Comparing two proportions</a></li>
<li class="chapter" data-level="10.4" data-path="week-5-lab.html"><a href="week-5-lab.html#comparing-two-distributions-1"><i class="fa fa-check"></i><b>10.4</b> Comparing two distributions</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="week-6-lecture.html"><a href="week-6-lecture.html"><i class="fa fa-check"></i><b>11</b> Week 6 Lecture</a>
<ul>
<li class="chapter" data-level="11.1" data-path="week-6-lecture.html"><a href="week-6-lecture.html#week-6-readings"><i class="fa fa-check"></i><b>11.1</b> Week 6 Readings</a></li>
<li class="chapter" data-level="11.2" data-path="week-6-lecture.html"><a href="week-6-lecture.html#family-wise-error-rates"><i class="fa fa-check"></i><b>11.2</b> Family-wise error rates</a></li>
<li class="chapter" data-level="11.3" data-path="week-6-lecture.html"><a href="week-6-lecture.html#how-do-we-sort-the-signal-from-the-noise"><i class="fa fa-check"></i><b>11.3</b> How do we sort the signal from the noise?</a></li>
</ul></li>
<li class="chapter" data-level="12" data-path="week-6-lab.html"><a href="week-6-lab.html"><i class="fa fa-check"></i><b>12</b> Week 6 Lab</a></li>
<li class="chapter" data-level="13" data-path="week-7-lecturelab.html"><a href="week-7-lecturelab.html"><i class="fa fa-check"></i><b>13</b> Week 7 Lecture/Lab</a>
<ul>
<li class="chapter" data-level="13.1" data-path="week-7-lecturelab.html"><a href="week-7-lecturelab.html#week-7-readings"><i class="fa fa-check"></i><b>13.1</b> Week 7 Readings</a></li>
<li class="chapter" data-level="13.2" data-path="week-7-lecturelab.html"><a href="week-7-lecturelab.html#introduction-to-plotting-in-r"><i class="fa fa-check"></i><b>13.2</b> Introduction to plotting in R</a></li>
<li class="chapter" data-level="13.3" data-path="week-7-lecturelab.html"><a href="week-7-lecturelab.html#box-plots"><i class="fa fa-check"></i><b>13.3</b> Box plots</a></li>
<li class="chapter" data-level="13.4" data-path="week-7-lecturelab.html"><a href="week-7-lecturelab.html#two-dimensional-data"><i class="fa fa-check"></i><b>13.4</b> Two-dimensional data</a></li>
<li class="chapter" data-level="13.5" data-path="week-7-lecturelab.html"><a href="week-7-lecturelab.html#three-dimensional-data"><i class="fa fa-check"></i><b>13.5</b> Three-dimensional data</a></li>
<li class="chapter" data-level="13.6" data-path="week-7-lecturelab.html"><a href="week-7-lecturelab.html#multiple-plots"><i class="fa fa-check"></i><b>13.6</b> Multiple plots</a></li>
</ul></li>
<li class="chapter" data-level="14" data-path="week-8-lecture.html"><a href="week-8-lecture.html"><i class="fa fa-check"></i><b>14</b> Week 8 Lecture</a>
<ul>
<li class="chapter" data-level="14.1" data-path="week-8-lecture.html"><a href="week-8-lecture.html#week-8-readings"><i class="fa fa-check"></i><b>14.1</b> Week 8 Readings</a></li>
<li class="chapter" data-level="14.2" data-path="week-8-lecture.html"><a href="week-8-lecture.html#warm-up"><i class="fa fa-check"></i><b>14.2</b> Warm-up</a></li>
<li class="chapter" data-level="14.3" data-path="week-8-lecture.html"><a href="week-8-lecture.html#the-aims-of-modelling-a-discussion-of-shmueli-2010"><i class="fa fa-check"></i><b>14.3</b> The aims of modelling – A discussion of Shmueli (2010)</a></li>
<li class="chapter" data-level="14.4" data-path="week-8-lecture.html"><a href="week-8-lecture.html#introduction-to-linear-models"><i class="fa fa-check"></i><b>14.4</b> Introduction to linear models</a></li>
<li class="chapter" data-level="14.5" data-path="week-8-lecture.html"><a href="week-8-lecture.html#linear-models-example-with-continuous-covariate"><i class="fa fa-check"></i><b>14.5</b> Linear models | example with continuous covariate</a></li>
<li class="chapter" data-level="14.6" data-path="week-8-lecture.html"><a href="week-8-lecture.html#resolving-overparameterization-using-contrasts"><i class="fa fa-check"></i><b>14.6</b> Resolving overparameterization using contrasts</a></li>
<li class="chapter" data-level="14.7" data-path="week-8-lecture.html"><a href="week-8-lecture.html#effect-codingtreatment-constrast"><i class="fa fa-check"></i><b>14.7</b> Effect coding/Treatment constrast</a></li>
<li class="chapter" data-level="14.8" data-path="week-8-lecture.html"><a href="week-8-lecture.html#helmert-contrasts"><i class="fa fa-check"></i><b>14.8</b> Helmert contrasts</a></li>
<li class="chapter" data-level="14.9" data-path="week-8-lecture.html"><a href="week-8-lecture.html#sum-to-zero-contrasts"><i class="fa fa-check"></i><b>14.9</b> Sum-to-zero contrasts</a></li>
<li class="chapter" data-level="14.10" data-path="week-8-lecture.html"><a href="week-8-lecture.html#polynomial-contrasts"><i class="fa fa-check"></i><b>14.10</b> Polynomial contrasts</a></li>
<li class="chapter" data-level="14.11" data-path="week-8-lecture.html"><a href="week-8-lecture.html#visualizing-hypotheses-for-different-coding-schemes"><i class="fa fa-check"></i><b>14.11</b> Visualizing hypotheses for different coding schemes</a></li>
<li class="chapter" data-level="14.12" data-path="week-8-lecture.html"><a href="week-8-lecture.html#orthogonal-vs.-non-orthogonal-contrasts"><i class="fa fa-check"></i><b>14.12</b> Orthogonal vs. Non-orthogonal contrasts</a></li>
<li class="chapter" data-level="14.13" data-path="week-8-lecture.html"><a href="week-8-lecture.html#error-structure-of-linear-models"><i class="fa fa-check"></i><b>14.13</b> Error structure of linear models</a></li>
</ul></li>
<li class="chapter" data-level="15" data-path="week-8-lab.html"><a href="week-8-lab.html"><i class="fa fa-check"></i><b>15</b> Week 8 Lab</a>
<ul>
<li class="chapter" data-level="15.1" data-path="week-8-lab.html"><a href="week-8-lab.html#covariate-as-number-vs.-covariate-as-factor"><i class="fa fa-check"></i><b>15.1</b> Covariate as number vs. covariate as factor</a></li>
<li class="chapter" data-level="15.2" data-path="week-8-lab.html"><a href="week-8-lab.html#helmert-contrasts-in-r"><i class="fa fa-check"></i><b>15.2</b> Helmert contrasts in R</a></li>
<li class="chapter" data-level="15.3" data-path="week-8-lab.html"><a href="week-8-lab.html#polynomial-contrasts-in-r"><i class="fa fa-check"></i><b>15.3</b> Polynomial contrasts in R</a></li>
</ul></li>
<li class="chapter" data-level="16" data-path="week-9-lecture.html"><a href="week-9-lecture.html"><i class="fa fa-check"></i><b>16</b> Week 9 Lecture</a>
<ul>
<li class="chapter" data-level="16.1" data-path="week-9-lecture.html"><a href="week-9-lecture.html#week-9-readings"><i class="fa fa-check"></i><b>16.1</b> Week 9 Readings</a></li>
<li class="chapter" data-level="16.2" data-path="week-9-lecture.html"><a href="week-9-lecture.html#correlation"><i class="fa fa-check"></i><b>16.2</b> Correlation</a></li>
<li class="chapter" data-level="16.3" data-path="week-9-lecture.html"><a href="week-9-lecture.html#hypothesis-testing---pearsons-r"><i class="fa fa-check"></i><b>16.3</b> Hypothesis testing - Pearson’s <em>r</em></a></li>
<li class="chapter" data-level="16.4" data-path="week-9-lecture.html"><a href="week-9-lecture.html#fishers-z"><i class="fa fa-check"></i><b>16.4</b> Fisher’s <span class="math inline">\(z\)</span></a></li>
<li class="chapter" data-level="16.5" data-path="week-9-lecture.html"><a href="week-9-lecture.html#regression"><i class="fa fa-check"></i><b>16.5</b> Regression</a></li>
<li class="chapter" data-level="16.6" data-path="week-9-lecture.html"><a href="week-9-lecture.html#estimating-the-slope-and-intercept-in-linear-regression"><i class="fa fa-check"></i><b>16.6</b> Estimating the slope and intercept in linear regression</a></li>
<li class="chapter" data-level="16.7" data-path="week-9-lecture.html"><a href="week-9-lecture.html#ok-now-the-other-derivation-for-slope-and-intercept"><i class="fa fa-check"></i><b>16.7</b> OK, now the “other” derivation for slope and intercept</a></li>
<li class="chapter" data-level="16.8" data-path="week-9-lecture.html"><a href="week-9-lecture.html#assumptions-of-regression"><i class="fa fa-check"></i><b>16.8</b> Assumptions of regression</a></li>
<li class="chapter" data-level="16.9" data-path="week-9-lecture.html"><a href="week-9-lecture.html#confidence-vs.-prediction-intervals"><i class="fa fa-check"></i><b>16.9</b> Confidence vs. Prediction intervals</a></li>
<li class="chapter" data-level="16.10" data-path="week-9-lecture.html"><a href="week-9-lecture.html#how-do-we-know-if-our-model-is-any-good"><i class="fa fa-check"></i><b>16.10</b> How do we know if our model is any good?</a></li>
<li class="chapter" data-level="16.11" data-path="week-9-lecture.html"><a href="week-9-lecture.html#robust-regression"><i class="fa fa-check"></i><b>16.11</b> Robust regression</a></li>
<li class="chapter" data-level="16.12" data-path="week-9-lecture.html"><a href="week-9-lecture.html#type-i-and-type-ii-regression"><i class="fa fa-check"></i><b>16.12</b> Type I and Type II Regression</a></li>
<li class="chapter" data-level="16.13" data-path="week-9-lecture.html"><a href="week-9-lecture.html#W9FAQ"><i class="fa fa-check"></i><b>16.13</b> Week 9 FAQ</a></li>
</ul></li>
<li class="chapter" data-level="17" data-path="week-9-lab.html"><a href="week-9-lab.html"><i class="fa fa-check"></i><b>17</b> Week 9 Lab</a>
<ul>
<li class="chapter" data-level="17.1" data-path="week-9-lab.html"><a href="week-9-lab.html#correlation-1"><i class="fa fa-check"></i><b>17.1</b> Correlation</a></li>
<li class="chapter" data-level="17.2" data-path="week-9-lab.html"><a href="week-9-lab.html#linear-modelling"><i class="fa fa-check"></i><b>17.2</b> Linear modelling</a></li>
<li class="chapter" data-level="17.3" data-path="week-9-lab.html"><a href="week-9-lab.html#centering-the-covariates"><i class="fa fa-check"></i><b>17.3</b> Centering the covariates</a></li>
<li class="chapter" data-level="17.4" data-path="week-9-lab.html"><a href="week-9-lab.html#weighted-regression"><i class="fa fa-check"></i><b>17.4</b> Weighted regression</a></li>
<li class="chapter" data-level="17.5" data-path="week-9-lab.html"><a href="week-9-lab.html#robust-regression-1"><i class="fa fa-check"></i><b>17.5</b> Robust regression</a></li>
<li class="chapter" data-level="17.6" data-path="week-9-lab.html"><a href="week-9-lab.html#bootstrapping-standard-errors-for-robust-regression"><i class="fa fa-check"></i><b>17.6</b> Bootstrapping standard errors for robust regression</a></li>
<li class="chapter" data-level="17.7" data-path="week-9-lab.html"><a href="week-9-lab.html#type-i-vs.-type-ii-regression-the-smatr-package"><i class="fa fa-check"></i><b>17.7</b> Type I vs. Type II regression: The ‘smatr’ package</a></li>
</ul></li>
<li class="chapter" data-level="18" data-path="week-10-lecture.html"><a href="week-10-lecture.html"><i class="fa fa-check"></i><b>18</b> Week 10 Lecture</a>
<ul>
<li class="chapter" data-level="18.1" data-path="week-10-lecture.html"><a href="week-10-lecture.html#week-10-readings"><i class="fa fa-check"></i><b>18.1</b> Week 10 Readings</a></li>
<li class="chapter" data-level="18.2" data-path="week-10-lecture.html"><a href="week-10-lecture.html#week-10-outline"><i class="fa fa-check"></i><b>18.2</b> Week 10 outline</a></li>
<li class="chapter" data-level="18.3" data-path="week-10-lecture.html"><a href="week-10-lecture.html#an-example"><i class="fa fa-check"></i><b>18.3</b> An example</a></li>
<li class="chapter" data-level="18.4" data-path="week-10-lecture.html"><a href="week-10-lecture.html#generalized-linear-models"><i class="fa fa-check"></i><b>18.4</b> Generalized linear models</a></li>
<li class="chapter" data-level="18.5" data-path="week-10-lecture.html"><a href="week-10-lecture.html#logistic-regression"><i class="fa fa-check"></i><b>18.5</b> Logistic regression</a></li>
<li class="chapter" data-level="18.6" data-path="week-10-lecture.html"><a href="week-10-lecture.html#fitting-a-glm"><i class="fa fa-check"></i><b>18.6</b> Fitting a GLM</a></li>
<li class="chapter" data-level="18.7" data-path="week-10-lecture.html"><a href="week-10-lecture.html#poisson-regression"><i class="fa fa-check"></i><b>18.7</b> Poisson regression</a></li>
<li class="chapter" data-level="18.8" data-path="week-10-lecture.html"><a href="week-10-lecture.html#deviance"><i class="fa fa-check"></i><b>18.8</b> Deviance</a></li>
<li class="chapter" data-level="18.9" data-path="week-10-lecture.html"><a href="week-10-lecture.html#other-methods-loess-splines-gams"><i class="fa fa-check"></i><b>18.9</b> Other methods – LOESS, splines, GAMs</a></li>
</ul></li>
<li class="chapter" data-level="19" data-path="week-10-lab.html"><a href="week-10-lab.html"><i class="fa fa-check"></i><b>19</b> Week 10 Lab</a>
<ul>
<li class="chapter" data-level="19.1" data-path="week-10-lab.html"><a href="week-10-lab.html#discussion-of-challenger-analysis"><i class="fa fa-check"></i><b>19.1</b> Discussion of Challenger analysis</a></li>
<li class="chapter" data-level="19.2" data-path="week-10-lab.html"><a href="week-10-lab.html#weighted-linear-regression"><i class="fa fa-check"></i><b>19.2</b> Weighted linear regression</a></li>
<li class="chapter" data-level="19.3" data-path="week-10-lab.html"><a href="week-10-lab.html#logistic-regression-practice"><i class="fa fa-check"></i><b>19.3</b> Logistic regression practice</a></li>
<li class="chapter" data-level="19.4" data-path="week-10-lab.html"><a href="week-10-lab.html#poisson-regression-practice"><i class="fa fa-check"></i><b>19.4</b> Poisson regression practice</a></li>
<li class="chapter" data-level="19.5" data-path="week-10-lab.html"><a href="week-10-lab.html#getting-a-feel-for-deviance"><i class="fa fa-check"></i><b>19.5</b> Getting a feel for Deviance</a></li>
<li class="chapter" data-level="19.6" data-path="week-10-lab.html"><a href="week-10-lab.html#generalized-additive-models"><i class="fa fa-check"></i><b>19.6</b> Generalized Additive Models</a></li>
</ul></li>
<li class="chapter" data-level="20" data-path="week-11-lecture.html"><a href="week-11-lecture.html"><i class="fa fa-check"></i><b>20</b> Week 11 Lecture</a>
<ul>
<li class="chapter" data-level="20.1" data-path="week-11-lecture.html"><a href="week-11-lecture.html#week-11-readings"><i class="fa fa-check"></i><b>20.1</b> Week 11 Readings</a></li>
<li class="chapter" data-level="20.2" data-path="week-11-lecture.html"><a href="week-11-lecture.html#week-11-outline"><i class="fa fa-check"></i><b>20.2</b> Week 11 outline</a>
<ul>
<li class="chapter" data-level="20.2.1" data-path="week-11-lecture.html"><a href="week-11-lecture.html#variation-within-treatment-group"><i class="fa fa-check"></i><b>20.2.1</b> Variation within treatment group</a></li>
<li class="chapter" data-level="20.2.2" data-path="week-11-lecture.html"><a href="week-11-lecture.html#variation-among-treatment-group-means"><i class="fa fa-check"></i><b>20.2.2</b> Variation among treatment group means</a></li>
<li class="chapter" data-level="20.2.3" data-path="week-11-lecture.html"><a href="week-11-lecture.html#comparing-variance-components"><i class="fa fa-check"></i><b>20.2.3</b> Comparing variance components</a></li>
</ul></li>
<li class="chapter" data-level="20.3" data-path="week-11-lecture.html"><a href="week-11-lecture.html#comparing-variance-components-1"><i class="fa fa-check"></i><b>20.3</b> Comparing variance components</a></li>
<li class="chapter" data-level="20.4" data-path="week-11-lecture.html"><a href="week-11-lecture.html#two-ways-to-estimate-variance"><i class="fa fa-check"></i><b>20.4</b> Two ways to estimate variance</a></li>
<li class="chapter" data-level="20.5" data-path="week-11-lecture.html"><a href="week-11-lecture.html#single-factor-anova"><i class="fa fa-check"></i><b>20.5</b> Single-factor ANOVA</a></li>
<li class="chapter" data-level="20.6" data-path="week-11-lecture.html"><a href="week-11-lecture.html#fixed-effects-vs.-random-effects"><i class="fa fa-check"></i><b>20.6</b> Fixed effects vs. random effects</a></li>
<li class="chapter" data-level="20.7" data-path="week-11-lecture.html"><a href="week-11-lecture.html#post-hoc-tests"><i class="fa fa-check"></i><b>20.7</b> Post-hoc tests</a>
<ul>
<li class="chapter" data-level="20.7.1" data-path="week-11-lecture.html"><a href="week-11-lecture.html#tukeys-hsd"><i class="fa fa-check"></i><b>20.7.1</b> Tukey’s HSD</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="21" data-path="week-11-lab.html"><a href="week-11-lab.html"><i class="fa fa-check"></i><b>21</b> Week 11 Lab</a>
<ul>
<li class="chapter" data-level="21.1" data-path="week-11-lab.html"><a href="week-11-lab.html#rs-anova-functions"><i class="fa fa-check"></i><b>21.1</b> R’s ANOVA functions</a></li>
<li class="chapter" data-level="21.2" data-path="week-11-lab.html"><a href="week-11-lab.html#single-factor-anova-in-r"><i class="fa fa-check"></i><b>21.2</b> Single-factor ANOVA in R</a></li>
<li class="chapter" data-level="21.3" data-path="week-11-lab.html"><a href="week-11-lab.html#follow-up-analyses-to-anova"><i class="fa fa-check"></i><b>21.3</b> Follow up analyses to ANOVA</a></li>
<li class="chapter" data-level="21.4" data-path="week-11-lab.html"><a href="week-11-lab.html#more-practice-model-i-anova"><i class="fa fa-check"></i><b>21.4</b> More practice: Model I ANOVA</a></li>
<li class="chapter" data-level="21.5" data-path="week-11-lab.html"><a href="week-11-lab.html#more-practice-brief-intro-to-doing-model-ii-anova-in-r"><i class="fa fa-check"></i><b>21.5</b> More practice: Brief intro to doing Model II ANOVA in R</a></li>
</ul></li>
<li class="chapter" data-level="22" data-path="week-12-lecture.html"><a href="week-12-lecture.html"><i class="fa fa-check"></i><b>22</b> Week 12 Lecture</a>
<ul>
<li class="chapter" data-level="22.1" data-path="week-12-lecture.html"><a href="week-12-lecture.html#week-12-readings"><i class="fa fa-check"></i><b>22.1</b> Week 12 Readings</a></li>
<li class="chapter" data-level="22.2" data-path="week-12-lecture.html"><a href="week-12-lecture.html#week-12-outline"><i class="fa fa-check"></i><b>22.2</b> Week 12 outline</a></li>
<li class="chapter" data-level="22.3" data-path="week-12-lecture.html"><a href="week-12-lecture.html#review-anova-with-one-factor"><i class="fa fa-check"></i><b>22.3</b> Review: ANOVA with one factor</a></li>
<li class="chapter" data-level="22.4" data-path="week-12-lecture.html"><a href="week-12-lecture.html#anova-with-more-than-one-factor"><i class="fa fa-check"></i><b>22.4</b> ANOVA with more than one factor</a></li>
<li class="chapter" data-level="22.5" data-path="week-12-lecture.html"><a href="week-12-lecture.html#two-way-anova-factorial-designs"><i class="fa fa-check"></i><b>22.5</b> Two-way ANOVA factorial designs</a></li>
<li class="chapter" data-level="22.6" data-path="week-12-lecture.html"><a href="week-12-lecture.html#why-bother-with-random-effects"><i class="fa fa-check"></i><b>22.6</b> Why bother with random effects?</a></li>
<li class="chapter" data-level="22.7" data-path="week-12-lecture.html"><a href="week-12-lecture.html#mixed-model"><i class="fa fa-check"></i><b>22.7</b> Mixed model</a></li>
<li class="chapter" data-level="22.8" data-path="week-12-lecture.html"><a href="week-12-lecture.html#unbalanced-designs"><i class="fa fa-check"></i><b>22.8</b> Unbalanced designs</a>
<ul>
<li class="chapter" data-level="22.8.1" data-path="week-12-lecture.html"><a href="week-12-lecture.html#unbalanced-design-different-sample-sizes"><i class="fa fa-check"></i><b>22.8.1</b> Unbalanced design – Different sample sizes</a></li>
<li class="chapter" data-level="22.8.2" data-path="week-12-lecture.html"><a href="week-12-lecture.html#type-i-sequential-sums-of-squares"><i class="fa fa-check"></i><b>22.8.2</b> Type I (sequential) sums of squares</a></li>
<li class="chapter" data-level="22.8.3" data-path="week-12-lecture.html"><a href="week-12-lecture.html#type-ii-hierarchical-sums-of-squares"><i class="fa fa-check"></i><b>22.8.3</b> Type II (hierarchical) sums of squares</a></li>
<li class="chapter" data-level="22.8.4" data-path="week-12-lecture.html"><a href="week-12-lecture.html#type-iii-marginal-sums-of-squares"><i class="fa fa-check"></i><b>22.8.4</b> Type III (marginal) sums of squares</a></li>
<li class="chapter" data-level="22.8.5" data-path="week-12-lecture.html"><a href="week-12-lecture.html#comparing-type-i-ii-and-iii-ss"><i class="fa fa-check"></i><b>22.8.5</b> Comparing type I, II, and III SS</a></li>
</ul></li>
<li class="chapter" data-level="22.9" data-path="week-12-lecture.html"><a href="week-12-lecture.html#unbalanced-design-missing-cell"><i class="fa fa-check"></i><b>22.9</b> Unbalanced design – Missing cell</a></li>
<li class="chapter" data-level="22.10" data-path="week-12-lecture.html"><a href="week-12-lecture.html#two-factor-nested-anova"><i class="fa fa-check"></i><b>22.10</b> Two factor nested ANOVA</a>
<ul>
<li class="chapter" data-level="22.10.1" data-path="week-12-lecture.html"><a href="week-12-lecture.html#potential-issues-with-nested-designs"><i class="fa fa-check"></i><b>22.10.1</b> Potential issues with nested designs</a></li>
</ul></li>
<li class="chapter" data-level="22.11" data-path="week-12-lecture.html"><a href="week-12-lecture.html#experimental-design"><i class="fa fa-check"></i><b>22.11</b> Experimental design</a>
<ul>
<li class="chapter" data-level="22.11.1" data-path="week-12-lecture.html"><a href="week-12-lecture.html#completely-randomized-design"><i class="fa fa-check"></i><b>22.11.1</b> Completely randomized design</a></li>
<li class="chapter" data-level="22.11.2" data-path="week-12-lecture.html"><a href="week-12-lecture.html#randomized-block-design"><i class="fa fa-check"></i><b>22.11.2</b> Randomized block design</a></li>
<li class="chapter" data-level="22.11.3" data-path="week-12-lecture.html"><a href="week-12-lecture.html#latin-square-design"><i class="fa fa-check"></i><b>22.11.3</b> Latin square design</a></li>
<li class="chapter" data-level="22.11.4" data-path="week-12-lecture.html"><a href="week-12-lecture.html#split-plot-design"><i class="fa fa-check"></i><b>22.11.4</b> Split plot design</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="23" data-path="week-12-lab.html"><a href="week-12-lab.html"><i class="fa fa-check"></i><b>23</b> Week 12 Lab</a>
<ul>
<li class="chapter" data-level="23.1" data-path="week-12-lab.html"><a href="week-12-lab.html#example-1-two-way-factorial-anova-in-r"><i class="fa fa-check"></i><b>23.1</b> Example #1: Two-way factorial ANOVA in R</a></li>
<li class="chapter" data-level="23.2" data-path="week-12-lab.html"><a href="week-12-lab.html#example-2-nested-design"><i class="fa fa-check"></i><b>23.2</b> Example #2: Nested design</a></li>
<li class="chapter" data-level="23.3" data-path="week-12-lab.html"><a href="week-12-lab.html#example-3-nested-design"><i class="fa fa-check"></i><b>23.3</b> Example #3: Nested design</a></li>
<li class="chapter" data-level="23.4" data-path="week-12-lab.html"><a href="week-12-lab.html#example-4-randomized-block-design"><i class="fa fa-check"></i><b>23.4</b> Example #4: Randomized Block Design</a></li>
<li class="chapter" data-level="23.5" data-path="week-12-lab.html"><a href="week-12-lab.html#example-5-nested-design"><i class="fa fa-check"></i><b>23.5</b> Example #5: Nested design</a></li>
</ul></li>
<li class="chapter" data-level="24" data-path="week-13-lecture.html"><a href="week-13-lecture.html"><i class="fa fa-check"></i><b>24</b> Week 13 Lecture</a>
<ul>
<li class="chapter" data-level="24.1" data-path="week-13-lecture.html"><a href="week-13-lecture.html#week-13-readings"><i class="fa fa-check"></i><b>24.1</b> Week 13 Readings</a></li>
<li class="chapter" data-level="24.2" data-path="week-13-lecture.html"><a href="week-13-lecture.html#model-criticism"><i class="fa fa-check"></i><b>24.2</b> Model criticism</a></li>
<li class="chapter" data-level="24.3" data-path="week-13-lecture.html"><a href="week-13-lecture.html#residuals"><i class="fa fa-check"></i><b>24.3</b> Residuals</a></li>
<li class="chapter" data-level="24.4" data-path="week-13-lecture.html"><a href="week-13-lecture.html#leverage"><i class="fa fa-check"></i><b>24.4</b> Leverage</a></li>
<li class="chapter" data-level="24.5" data-path="week-13-lecture.html"><a href="week-13-lecture.html#influence"><i class="fa fa-check"></i><b>24.5</b> Influence</a></li>
<li class="chapter" data-level="24.6" data-path="week-13-lecture.html"><a href="week-13-lecture.html#comparing-residuals-leverage-and-influence"><i class="fa fa-check"></i><b>24.6</b> Comparing residuals, leverage, and influence</a></li>
<li class="chapter" data-level="24.7" data-path="week-13-lecture.html"><a href="week-13-lecture.html#residuals-for-glms"><i class="fa fa-check"></i><b>24.7</b> Residuals for GLMs</a></li>
<li class="chapter" data-level="24.8" data-path="week-13-lecture.html"><a href="week-13-lecture.html#model-selection-vs.-model-criticism"><i class="fa fa-check"></i><b>24.8</b> Model selection vs. model criticism</a></li>
<li class="chapter" data-level="24.9" data-path="week-13-lecture.html"><a href="week-13-lecture.html#comparing-two-models"><i class="fa fa-check"></i><b>24.9</b> Comparing two models</a>
<ul>
<li class="chapter" data-level="24.9.1" data-path="week-13-lecture.html"><a href="week-13-lecture.html#nested-or-not"><i class="fa fa-check"></i><b>24.9.1</b> Nested or not?</a></li>
<li class="chapter" data-level="24.9.2" data-path="week-13-lecture.html"><a href="week-13-lecture.html#likelihood-ratio-test-lrt"><i class="fa fa-check"></i><b>24.9.2</b> Likelihood Ratio Test (LRT)</a></li>
<li class="chapter" data-level="24.9.3" data-path="week-13-lecture.html"><a href="week-13-lecture.html#akaikes-information-criterion-aic"><i class="fa fa-check"></i><b>24.9.3</b> Akaike’s Information Criterion (AIC)</a></li>
<li class="chapter" data-level="24.9.4" data-path="week-13-lecture.html"><a href="week-13-lecture.html#bayesian-information-criterion-bic"><i class="fa fa-check"></i><b>24.9.4</b> Bayesian Information Criterion (BIC)</a></li>
<li class="chapter" data-level="24.9.5" data-path="week-13-lecture.html"><a href="week-13-lecture.html#comparing-lrt-and-aicbic"><i class="fa fa-check"></i><b>24.9.5</b> Comparing LRT and AIC/BIC</a></li>
</ul></li>
<li class="chapter" data-level="24.10" data-path="week-13-lecture.html"><a href="week-13-lecture.html#model-weighting"><i class="fa fa-check"></i><b>24.10</b> Model weighting</a></li>
<li class="chapter" data-level="24.11" data-path="week-13-lecture.html"><a href="week-13-lecture.html#stepwise-regression"><i class="fa fa-check"></i><b>24.11</b> Stepwise regression</a>
<ul>
<li class="chapter" data-level="24.11.1" data-path="week-13-lecture.html"><a href="week-13-lecture.html#criticism-of-stepwise-regression"><i class="fa fa-check"></i><b>24.11.1</b> Criticism of stepwise regression</a></li>
<li class="chapter" data-level="24.11.2" data-path="week-13-lecture.html"><a href="week-13-lecture.html#criticism-of-data-dredging"><i class="fa fa-check"></i><b>24.11.2</b> Criticism of data dredging</a></li>
<li class="chapter" data-level="24.11.3" data-path="week-13-lecture.html"><a href="week-13-lecture.html#final-thoughts-on-model-selection"><i class="fa fa-check"></i><b>24.11.3</b> Final thoughts on model selection</a></li>
</ul></li>
<li class="chapter" data-level="24.12" data-path="week-13-lecture.html"><a href="week-13-lecture.html#week-13-faq"><i class="fa fa-check"></i><b>24.12</b> Week 13 FAQ</a></li>
</ul></li>
<li class="chapter" data-level="25" data-path="week-13-lab.html"><a href="week-13-lab.html"><i class="fa fa-check"></i><b>25</b> Week 13 Lab</a>
<ul>
<li class="chapter" data-level="25.1" data-path="week-13-lab.html"><a href="week-13-lab.html#part-1-model-selection-model-comparison"><i class="fa fa-check"></i><b>25.1</b> Part 1: Model selection / model comparison</a></li>
<li class="chapter" data-level="25.2" data-path="week-13-lab.html"><a href="week-13-lab.html#model-selection-via-step-wise-regression"><i class="fa fa-check"></i><b>25.2</b> Model selection via step-wise regression</a></li>
<li class="chapter" data-level="25.3" data-path="week-13-lab.html"><a href="week-13-lab.html#part-2-model-criticism"><i class="fa fa-check"></i><b>25.3</b> Part 2: Model criticism</a></li>
</ul></li>
<li class="chapter" data-level="26" data-path="week-14-lecture.html"><a href="week-14-lecture.html"><i class="fa fa-check"></i><b>26</b> Week 14 Lecture</a>
<ul>
<li class="chapter" data-level="26.1" data-path="week-14-lecture.html"><a href="week-14-lecture.html#week-14-readings"><i class="fa fa-check"></i><b>26.1</b> Week 14 Readings</a></li>
<li class="chapter" data-level="26.2" data-path="week-14-lecture.html"><a href="week-14-lecture.html#what-does-multivariate-mean"><i class="fa fa-check"></i><b>26.2</b> What does ‘multivariate’ mean?</a></li>
<li class="chapter" data-level="26.3" data-path="week-14-lecture.html"><a href="week-14-lecture.html#multivariate-associations"><i class="fa fa-check"></i><b>26.3</b> Multivariate associations</a></li>
<li class="chapter" data-level="26.4" data-path="week-14-lecture.html"><a href="week-14-lecture.html#model-criticism-for-multivariate-analyses"><i class="fa fa-check"></i><b>26.4</b> Model criticism for multivariate analyses</a>
<ul>
<li class="chapter" data-level="26.4.1" data-path="week-14-lecture.html"><a href="week-14-lecture.html#transforming-your-data"><i class="fa fa-check"></i><b>26.4.1</b> Transforming your data</a></li>
</ul></li>
<li class="chapter" data-level="26.5" data-path="week-14-lecture.html"><a href="week-14-lecture.html#standardizing-your-data"><i class="fa fa-check"></i><b>26.5</b> Standardizing your data</a></li>
<li class="chapter" data-level="26.6" data-path="week-14-lecture.html"><a href="week-14-lecture.html#multivariate-outliers"><i class="fa fa-check"></i><b>26.6</b> Multivariate outliers</a></li>
<li class="chapter" data-level="26.7" data-path="week-14-lecture.html"><a href="week-14-lecture.html#brief-overview-of-multivariate-analyses"><i class="fa fa-check"></i><b>26.7</b> Brief overview of multivariate analyses</a></li>
<li class="chapter" data-level="26.8" data-path="week-14-lecture.html"><a href="week-14-lecture.html#manova-and-dfa"><i class="fa fa-check"></i><b>26.8</b> MANOVA and DFA</a></li>
<li class="chapter" data-level="26.9" data-path="week-14-lecture.html"><a href="week-14-lecture.html#scaling-or-ordination-techniques"><i class="fa fa-check"></i><b>26.9</b> Scaling or ordination techniques</a></li>
<li class="chapter" data-level="26.10" data-path="week-14-lecture.html"><a href="week-14-lecture.html#principal-components-analysis-pca"><i class="fa fa-check"></i><b>26.10</b> Principal components analysis (PCA)</a></li>
<li class="chapter" data-level="26.11" data-path="week-14-lecture.html"><a href="week-14-lecture.html#principal-components-analysis-pca-1"><i class="fa fa-check"></i><b>26.11</b> Principal components analysis (PCA)</a></li>
<li class="chapter" data-level="26.12" data-path="week-14-lecture.html"><a href="week-14-lecture.html#pca-in-r"><i class="fa fa-check"></i><b>26.12</b> PCA in R</a></li>
<li class="chapter" data-level="26.13" data-path="week-14-lecture.html"><a href="week-14-lecture.html#missing-data"><i class="fa fa-check"></i><b>26.13</b> Missing data</a></li>
<li class="chapter" data-level="26.14" data-path="week-14-lecture.html"><a href="week-14-lecture.html#imputing-missing-data"><i class="fa fa-check"></i><b>26.14</b> Imputing missing data</a></li>
</ul></li>
<li class="chapter" data-level="27" data-path="week-14-lab.html"><a href="week-14-lab.html"><i class="fa fa-check"></i><b>27</b> Week 14 Lab</a>
<ul>
<li class="chapter" data-level="27.1" data-path="week-14-lab.html"><a href="week-14-lab.html#missing-at-random---practice-with-glms"><i class="fa fa-check"></i><b>27.1</b> Missing at random - practice with GLMs</a></li>
<li class="chapter" data-level="27.2" data-path="week-14-lab.html"><a href="week-14-lab.html#finally-a-word-about-grades"><i class="fa fa-check"></i><b>27.2</b> Finally, a word about grades</a></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Biometry Lecture and Lab Notes</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="week-12-lab" class="section level1 hasAnchor" number="23">
<h1><span class="header-section-number">23</span> Week 12 Lab<a href="week-12-lab.html#week-12-lab" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<p>Today we will discuss Hurlbert’s <a href="https://github.com/hlynch/Biometry2020/tree/master/_data/Hurlbert.pdf">famous paper</a> on pseudoreplication. You can also find an interview with Hurlbert <a href="https://podcasts.apple.com/us/podcast/get-real-stuart-hurlbert-on-pseudoreplication-other/id426676729?i=1000368631395">here</a>.</p>
<p>There are 5 parts to this week’s lab:</p>
<ol style="list-style-type: decimal">
<li>Example #1: Two-way factorial ANOVA in R</li>
<li>Example #2: Nested deisgn</li>
<li>Example #3: Nested design</li>
<li>Example #4: Randomized block design</li>
<li>Example #5: Nested design</li>
</ol>
<div id="example-1-two-way-factorial-anova-in-r" class="section level2 hasAnchor" number="23.1">
<h2><span class="header-section-number">23.1</span> Example #1: Two-way factorial ANOVA in R<a href="week-12-lab.html#example-1-two-way-factorial-anova-in-r" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Two-way ANOVA in R is a lot like one-way ANOVA in R, except now we have a second covariate in the model equation. We will go through a two-way example using the same data on income and education that we used last week.</p>
<div class="sourceCode" id="cb752"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb752-1"><a href="week-12-lab.html#cb752-1" tabindex="-1"></a>salaries<span class="ot">&lt;-</span><span class="fu">read.csv</span>(<span class="st">&quot;_data/TwoWayANOVAdata.csv&quot;</span>)</span>
<span id="cb752-2"><a href="week-12-lab.html#cb752-2" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow=</span><span class="fu">c</span>(<span class="dv">2</span>,<span class="dv">1</span>))</span>
<span id="cb752-3"><a href="week-12-lab.html#cb752-3" tabindex="-1"></a><span class="fu">boxplot</span>(salaries<span class="sc">$</span>Salary<span class="sc">~</span>salaries<span class="sc">$</span>Gender,<span class="at">ylab=</span><span class="st">&quot;Salary&quot;</span>)</span>
<span id="cb752-4"><a href="week-12-lab.html#cb752-4" tabindex="-1"></a><span class="fu">boxplot</span>(salaries<span class="sc">$</span>Salary<span class="sc">~</span>salaries<span class="sc">$</span>Education,<span class="at">ylab=</span><span class="st">&quot;Salary&quot;</span>)</span></code></pre></div>
<p><img src="Week-12-lab_files/figure-html/unnamed-chunk-2-1.png" width="672" /></p>
<p>NB: The data we are using this week are the original (unbalanced) version of the data we used last week. These data are unbalanced, which will have important consequences for the ANOVA as we will see.</p>
<p>Let’s stop for a second and figure out how we can look at the data:</p>
<div class="sourceCode" id="cb753"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb753-1"><a href="week-12-lab.html#cb753-1" tabindex="-1"></a><span class="fu">summary</span>(salaries)</span></code></pre></div>
<pre><code>##      Salary         Gender           Education        
##  Min.   :15.00   Length:31          Length:31         
##  1st Qu.:20.50   Class :character   Class :character  
##  Median :25.00   Mode  :character   Mode  :character  
##  Mean   :23.97                                        
##  3rd Qu.:27.00                                        
##  Max.   :32.00</code></pre>
<div class="sourceCode" id="cb755"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb755-1"><a href="week-12-lab.html#cb755-1" tabindex="-1"></a><span class="fu">str</span>(salaries)</span></code></pre></div>
<pre><code>## &#39;data.frame&#39;:    31 obs. of  3 variables:
##  $ Salary   : int  24 26 25 24 27 24 27 23 30 27 ...
##  $ Gender   : chr  &quot;Female&quot; &quot;Female&quot; &quot;Female&quot; &quot;Female&quot; ...
##  $ Education: chr  &quot;Masters&quot; &quot;Masters&quot; &quot;Masters&quot; &quot;Masters&quot; ...</code></pre>
<div class="sourceCode" id="cb757"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb757-1"><a href="week-12-lab.html#cb757-1" tabindex="-1"></a><span class="fu">head</span>(salaries)</span></code></pre></div>
<pre><code>##   Salary Gender Education
## 1     24 Female   Masters
## 2     26 Female   Masters
## 3     25 Female   Masters
## 4     24 Female   Masters
## 5     27 Female   Masters
## 6     24 Female   Masters</code></pre>
<p>I’m going to show you another nice way of looking at ANOVA data which defines a new function which calculates the mean and its standard error and prints it out in a nice format. Don’t worry too much about the details, but I include the script here so you have it in case it is helpful for you later…</p>
<div class="sourceCode" id="cb759"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb759-1"><a href="week-12-lab.html#cb759-1" tabindex="-1"></a>meansd<span class="ot">&lt;-</span><span class="cf">function</span>(x)</span>
<span id="cb759-2"><a href="week-12-lab.html#cb759-2" tabindex="-1"></a>  {</span>
<span id="cb759-3"><a href="week-12-lab.html#cb759-3" tabindex="-1"></a>  tmp.mean<span class="ot">&lt;-</span><span class="fu">format</span>(<span class="fu">mean</span>(x),<span class="at">digits=</span><span class="dv">3</span>)</span>
<span id="cb759-4"><a href="week-12-lab.html#cb759-4" tabindex="-1"></a>  tmp.sd<span class="ot">&lt;-</span><span class="fu">format</span>(<span class="fu">apply</span>(x,<span class="dv">2</span>,sd),<span class="at">digits=</span><span class="dv">3</span>)</span>
<span id="cb759-5"><a href="week-12-lab.html#cb759-5" tabindex="-1"></a>  mean.sd<span class="ot">&lt;-</span><span class="fu">paste</span>(tmp.mean, <span class="st">&quot; (&quot;</span>,tmp.sd,<span class="st">&quot;)&quot;</span>, <span class="at">sep=</span><span class="st">&quot;&quot;</span>)</span>
<span id="cb759-6"><a href="week-12-lab.html#cb759-6" tabindex="-1"></a>  mean.sd<span class="ot">&lt;-</span><span class="fu">as.matrix</span>(mean.sd)</span>
<span id="cb759-7"><a href="week-12-lab.html#cb759-7" tabindex="-1"></a>  <span class="fu">names</span>(mean.sd)<span class="ot">&lt;-</span> <span class="st">&quot;Mean (SD)&quot;</span></span>
<span id="cb759-8"><a href="week-12-lab.html#cb759-8" tabindex="-1"></a>  <span class="fu">return</span>(mean.sd)</span>
<span id="cb759-9"><a href="week-12-lab.html#cb759-9" tabindex="-1"></a>  }</span>
<span id="cb759-10"><a href="week-12-lab.html#cb759-10" tabindex="-1"></a></span>
<span id="cb759-11"><a href="week-12-lab.html#cb759-11" tabindex="-1"></a><span class="fu">library</span>(rms)  <span class="co">#the function &quot;summary&quot; uses the rms package</span></span></code></pre></div>
<pre><code>## Loading required package: Hmisc</code></pre>
<pre><code>## Loading required package: lattice</code></pre>
<pre><code>## Loading required package: survival</code></pre>
<pre><code>## Loading required package: Formula</code></pre>
<pre><code>## Loading required package: ggplot2</code></pre>
<pre><code>## 
## Attaching package: &#39;Hmisc&#39;</code></pre>
<pre><code>## The following objects are masked from &#39;package:base&#39;:
## 
##     format.pval, units</code></pre>
<pre><code>## Loading required package: SparseM</code></pre>
<pre><code>## 
## Attaching package: &#39;SparseM&#39;</code></pre>
<pre><code>## The following object is masked from &#39;package:base&#39;:
## 
##     backsolve</code></pre>
<pre><code>## Warning in .recacheSubclasses(def@className, def, env): undefined subclass
## &quot;numericVector&quot; of class &quot;Mnumeric&quot;; definition not updated</code></pre>
<div class="sourceCode" id="cb771"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb771-1"><a href="week-12-lab.html#cb771-1" tabindex="-1"></a><span class="fu">summary</span>(Salary<span class="sc">~</span>Education<span class="sc">+</span>Gender,<span class="at">data=</span>salaries,<span class="at">method=</span><span class="st">&quot;cross&quot;</span>,<span class="at">fun=</span>meansd)</span></code></pre></div>
<pre><code>## 
##  meansd by Education, Gender 
## 
## +------+
## |     N|
## |Salary|
## +------+
## +---------+-----------+-----------+-----------+
## |Education|   Female  |    Male   |    ALL    |
## +---------+-----------+-----------+-----------+
## |  Masters|         8 |         3 |         11|
## |         |25 (1.51)  |27 (2)     |25.5 (1.81)|
## +---------+-----------+-----------+-----------+
## |No degree|         4 |         7 |         11|
## |         |17 (2.16)  |20 (1.41)  |18.9 (2.21)|
## +---------+-----------+-----------+-----------+
## |      PhD|         4 |         5 |         9 |
## |         |29.2 (2.22)|27.4 (1.67)|28.2 (2.05)|
## +---------+-----------+-----------+-----------+
## |      ALL|         16|         15|         31|
## |         |24.1 (4.89)|23.9 (4.03)|24 (4.42)  |
## +---------+-----------+-----------+-----------+</code></pre>
<p>This is a quick and dirty way to look at the raw data to make sense of the model output to come. Note that you could stick this inside ‘latex()’ and it would make a latex ready formatted table for you.</p>
<p>Back to the modelling…</p>
<p>Note that</p>
<pre><code>Salary~Education+Gender+Education:Gender</code></pre>
<p>is the same as</p>
<pre><code>Salary~Education*Gender</code></pre>
<p>since the * says “consider Education and Gender and all interactions”.</p>
<p>For reasons that will become clear in a second, we will use the first notation for now.</p>
<div class="sourceCode" id="cb775"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb775-1"><a href="week-12-lab.html#cb775-1" tabindex="-1"></a>lm.fit<span class="fl">.2</span>way<span class="ot">&lt;-</span><span class="fu">lm</span>(Salary<span class="sc">~</span>Education<span class="sc">+</span>Gender<span class="sc">+</span>Education<span class="sc">:</span>Gender,<span class="at">data=</span>salaries)</span>
<span id="cb775-2"><a href="week-12-lab.html#cb775-2" tabindex="-1"></a><span class="fu">summary</span>(lm.fit<span class="fl">.2</span>way)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = Salary ~ Education + Gender + Education:Gender, 
##     data = salaries)
## 
## Residuals:
##    Min     1Q Median     3Q    Max 
## -2.250 -1.125  0.000  1.000  3.000 
## 
## Coefficients:
##                               Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)                    25.0000     0.6162  40.569  &lt; 2e-16 ***
## EducationNo degree             -8.0000     1.0674  -7.495 7.55e-08 ***
## EducationPhD                    4.2500     1.0674   3.982 0.000519 ***
## GenderMale                      2.0000     1.1800   1.695 0.102516    
## EducationNo degree:GenderMale   1.0000     1.6081   0.622 0.539664    
## EducationPhD:GenderMale        -3.8500     1.6612  -2.318 0.028945 *  
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 1.743 on 25 degrees of freedom
## Multiple R-squared:  0.8706, Adjusted R-squared:  0.8447 
## F-statistic: 33.64 on 5 and 25 DF,  p-value: 2.509e-10</code></pre>
<div class="sourceCode" id="cb777"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb777-1"><a href="week-12-lab.html#cb777-1" tabindex="-1"></a><span class="fu">anova</span>(lm.fit<span class="fl">.2</span>way)</span></code></pre></div>
<pre><code>## Analysis of Variance Table
## 
## Response: Salary
##                  Df Sum Sq Mean Sq F value    Pr(&gt;F)    
## Education         2 471.78 235.888 77.6458 1.882e-11 ***
## Gender            1   8.96   8.955  2.9478   0.09836 .  
## Education:Gender  2  30.29  15.143  4.9846   0.01507 *  
## Residuals        25  75.95   3.038                      
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>(Question: How do we interpret the intercept?)</p>
<p>Note that these effect sizes should make sense if we keep track of the correct usage of the interaction terms. The intercept is the mean salary of a Female with a Masters degree (25k). We can re-create the other cells in the table above by adding or subtracting from the baseline the effects of swapping categories of gender or education.</p>
<p>For example, what is the mean salary of a man with a PhD. Going from the baseline condition of the intercept to a Man with a PhD we have to make two swaps: Female-&gt;Male and Masters-&gt;PhD. This involves both the main effects of Gender and Education but also the interaction between Gender and Education. Let’s do this stepwise:</p>
<p><span class="math display">\[
\mbox{Female&amp;Masters}=25 \\
\mbox{Change for a woman getting a PhD}=4.25 \\
------- \rightarrow\mbox{Women&amp;PhD}=25+4.25=29.25 \\
\mbox{Change for a Woman with PhD becoming a Man} = 2-3.85 = -1.85\\  
------- \rightarrow \mbox{Man&amp;PhD} = 29.25-1.85=27.4
\]</span></p>
<p>This is exactly what the table shows as well. Note that because of the interaction, a woman with a PhD is better off staying a woman because the benefit of getting a PhD is much bigger for a woman than for a man and this more than compensates for the negative effect being female has on average salary. Another way of thinking about it would be to do the gender swap first:</p>
<p><span class="math display">\[
\mbox{Female&amp;Masters}=25 \\
\mbox{Change for a Woman with Masters becoming a Man} = 2 \\
------- \rightarrow \mbox{Man&amp;Masters} = 25+2 = 27 \mbox{    [Magic, no additional skills required! :) ]}\\
\mbox{Change for a Man getting a PhD}=4.25-3.85 =0.4 \\
------- \rightarrow \mbox{Man&amp;PhD}=27+0.4=27.4 \\
\]</span></p>
<p>Now try doing the “same” analysis but switching the order of inputs</p>
<div class="sourceCode" id="cb779"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb779-1"><a href="week-12-lab.html#cb779-1" tabindex="-1"></a>lm.fit<span class="fl">.2</span>way<span class="ot">&lt;-</span><span class="fu">lm</span>(Salary<span class="sc">~</span>Gender<span class="sc">+</span>Education<span class="sc">+</span>Gender<span class="sc">:</span>Education,<span class="at">data=</span>salaries)</span>
<span id="cb779-2"><a href="week-12-lab.html#cb779-2" tabindex="-1"></a><span class="fu">summary</span>(lm.fit<span class="fl">.2</span>way)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = Salary ~ Gender + Education + Gender:Education, 
##     data = salaries)
## 
## Residuals:
##    Min     1Q Median     3Q    Max 
## -2.250 -1.125  0.000  1.000  3.000 
## 
## Coefficients:
##                               Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)                    25.0000     0.6162  40.569  &lt; 2e-16 ***
## GenderMale                      2.0000     1.1800   1.695 0.102516    
## EducationNo degree             -8.0000     1.0674  -7.495 7.55e-08 ***
## EducationPhD                    4.2500     1.0674   3.982 0.000519 ***
## GenderMale:EducationNo degree   1.0000     1.6081   0.622 0.539664    
## GenderMale:EducationPhD        -3.8500     1.6612  -2.318 0.028945 *  
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 1.743 on 25 degrees of freedom
## Multiple R-squared:  0.8706, Adjusted R-squared:  0.8447 
## F-statistic: 33.64 on 5 and 25 DF,  p-value: 2.509e-10</code></pre>
<div class="sourceCode" id="cb781"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb781-1"><a href="week-12-lab.html#cb781-1" tabindex="-1"></a><span class="fu">anova</span>(lm.fit<span class="fl">.2</span>way)</span></code></pre></div>
<pre><code>## Analysis of Variance Table
## 
## Response: Salary
##                  Df Sum Sq Mean Sq F value    Pr(&gt;F)    
## Gender            1   0.30   0.297  0.0977   0.75716    
## Education         2 480.43 240.217 79.0708 1.547e-11 ***
## Gender:Education  2  30.29  15.143  4.9846   0.01507 *  
## Residuals        25  75.95   3.038                      
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>Did you get the same answer? (No. In fact, Gender is no longer significant the second way.)</p>
<p>Notice that while the ANOVA tables are different, the parameter estimates and their standard errors/p-values are the same in both cases. Why? Remember when we were discussing multiple regression, we said that the coefficients in a multiple regression represented the slope of the “partial regression line” which is to be interpreted as the effect of that covariate holding all other predictor variables at their mean value. In other words, the multiple regression implicitly uses a Type III approach because that is typically what is of interest. Likewise, we are usually interested in the Type III sum of squares ANOVA table. The only problem is that this is not R’s default.</p>
<p>To get Type II and Type III sum of squares ANOVA tables, you have to use the ‘Anova’ function in the ‘car’ package.</p>
<p>Before moving on from this example, its worth thinking about a slightly simpler analysis in which you model income as a function of gender (men v. women) and education (Masters v. PhD). (Same as above but considering only two of the original three education levels.) Considering the 2-way ANOVA analysis for this, we may find ourselves asking the question “If you have a factorial design and you are going to include an interaction term, why bother doing a two-way ANOVA - why not just do two separate t-tests?”. In other words, the interaction allows for the effect of Education to differ for men and for women, so why not just do a t-test for men and a separate t-test for women? One issue is the concern over multiple comparisons. The other difference involves how error is estimated.</p>
<p>Let’s do the ANOVA first:</p>
<div class="sourceCode" id="cb783"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb783-1"><a href="week-12-lab.html#cb783-1" tabindex="-1"></a>salaries.v2<span class="ot">&lt;-</span>salaries[<span class="sc">-</span><span class="fu">which</span>(salaries<span class="sc">$</span>Education<span class="sc">==</span><span class="st">&quot;No degree&quot;</span>),]</span>
<span id="cb783-2"><a href="week-12-lab.html#cb783-2" tabindex="-1"></a><span class="fu">summary</span>(<span class="fu">lm</span>(Salary<span class="sc">~</span>Gender<span class="sc">+</span>Education<span class="sc">+</span>Gender<span class="sc">:</span>Education,<span class="at">data=</span>salaries.v2))</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = Salary ~ Gender + Education + Gender:Education, 
##     data = salaries.v2)
## 
## Residuals:
##    Min     1Q Median     3Q    Max 
## -2.250 -1.288 -0.200  1.250  2.750 
## 
## Coefficients:
##                         Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)              25.0000     0.6247  40.020   &lt;2e-16 ***
## GenderMale                2.0000     1.1962   1.672   0.1140    
## EducationPhD              4.2500     1.0820   3.928   0.0012 ** 
## GenderMale:EducationPhD  -3.8500     1.6840  -2.286   0.0362 *  
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 1.767 on 16 degrees of freedom
## Multiple R-squared:  0.5091, Adjusted R-squared:  0.417 
## F-statistic: 5.531 on 3 and 16 DF,  p-value: 0.008446</code></pre>
<p>Now lets do the analogous t-test, looking at the difference in salary between women with a Masters degree and women with a PhD:</p>
<div class="sourceCode" id="cb785"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb785-1"><a href="week-12-lab.html#cb785-1" tabindex="-1"></a><span class="fu">t.test</span>(salaries.v2<span class="sc">$</span>Salary[salaries.v2<span class="sc">$</span>Gender<span class="sc">==</span><span class="st">&quot;Female&quot;</span><span class="sc">&amp;</span>salaries.v2<span class="sc">$</span>Education<span class="sc">==</span><span class="st">&quot;Masters&quot;</span>],salaries.v2<span class="sc">$</span>Salary[salaries.v2<span class="sc">$</span>Gender<span class="sc">==</span><span class="st">&quot;Female&quot;</span><span class="sc">&amp;</span>salaries.v2<span class="sc">$</span>Education<span class="sc">==</span><span class="st">&quot;PhD&quot;</span>])</span></code></pre></div>
<pre><code>## 
##  Welch Two Sample t-test
## 
## data:  salaries.v2$Salary[salaries.v2$Gender == &quot;Female&quot; &amp; salaries.v2$Education == &quot;Masters&quot;] and salaries.v2$Salary[salaries.v2$Gender == &quot;Female&quot; &amp; salaries.v2$Education == &quot;PhD&quot;]
## t = -3.453, df = 4.4536, p-value = 0.02188
## alternative hypothesis: true difference in means is not equal to 0
## 95 percent confidence interval:
##  -7.5342704 -0.9657296
## sample estimates:
## mean of x mean of y 
##     25.00     29.25</code></pre>
<p>Notice that the difference in means is exactly what you would expect from the summary table from the lm() function (4.25) but the t-statistic (and hence the p-value) are now different. Why? In the lm(), data on both males and females are used to estimate the within-group error (in other words, the data are pooled to estimate MSwithin) whereas the t-test uses data for women only and therefore ends up with a slightly different estimate for the test statistic and the p-value.</p>
<p>Which is correct? It depends on whether you think that there is value in pooling the errors. It also depends on how concerned you are about multiple comparisons with the separate t-tests.</p>
</div>
<div id="example-2-nested-design" class="section level2 hasAnchor" number="23.2">
<h2><span class="header-section-number">23.2</span> Example #2: Nested design<a href="week-12-lab.html#example-2-nested-design" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>We will work through one of the classic examples from Sokal &amp; Rohlf in which we are looking at the effect of a treatment on rat livers. We have three treatments, two rats per treatment, three liver samples per rat, and two measurements of each liver sample. The experimental design is sketched out here:</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:unnamed-chunk-9"></span>
<img src="RatDesign.png" alt="Nested design of the rat experiment." width="100%" />
<p class="caption">
Figure 23.1: Nested design of the rat experiment.
</p>
</div>
<div class="sourceCode" id="cb787"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb787-1"><a href="week-12-lab.html#cb787-1" tabindex="-1"></a>rats<span class="ot">&lt;-</span><span class="fu">read.csv</span>(<span class="st">&quot;_data/rats.txt&quot;</span>,<span class="at">header=</span>T)</span>
<span id="cb787-2"><a href="week-12-lab.html#cb787-2" tabindex="-1"></a><span class="fu">attach</span>(rats)</span>
<span id="cb787-3"><a href="week-12-lab.html#cb787-3" tabindex="-1"></a>Treatment<span class="ot">&lt;-</span><span class="fu">factor</span>(TREAT)</span>
<span id="cb787-4"><a href="week-12-lab.html#cb787-4" tabindex="-1"></a>Rat<span class="ot">&lt;-</span><span class="fu">factor</span>(RAT)</span>
<span id="cb787-5"><a href="week-12-lab.html#cb787-5" tabindex="-1"></a>Liver<span class="ot">&lt;-</span><span class="fu">factor</span>(PREP)</span>
<span id="cb787-6"><a href="week-12-lab.html#cb787-6" tabindex="-1"></a><span class="fu">anova</span>(<span class="fu">lm</span>(GLYCO<span class="sc">~</span>TREAT))</span></code></pre></div>
<pre><code>## Analysis of Variance Table
## 
## Response: GLYCO
##           Df Sum Sq Mean Sq F value    Pr(&gt;F)    
## TREAT      2 1557.6  778.78  14.498 3.031e-05 ***
## Residuals 33 1772.7   53.72                      
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>It looks like Treatment is highly significant! But…we made a big mistake here because we have assumed that all 36 liver measurements are independent samples when we know that they are not because they only come from 6 rats (2 for each treatment).</p>
<p>What happens if we simply average the Glycogen context for each rat and redo the ANOVA?</p>
<div class="sourceCode" id="cb789"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb789-1"><a href="week-12-lab.html#cb789-1" tabindex="-1"></a><span class="fu">tapply</span>(GLYCO,<span class="fu">list</span>(TREAT,RAT),mean)</span></code></pre></div>
<pre><code>##                   Rat1  Rat2     Rat3     Rat4     Rat5 Rat6
## Compound217         NA    NA 149.6667 152.3333       NA   NA
## Compound217Sugar    NA    NA       NA       NA 134.3333  136
## Control          132.5 148.5       NA       NA       NA   NA</code></pre>
<div class="sourceCode" id="cb791"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb791-1"><a href="week-12-lab.html#cb791-1" tabindex="-1"></a><span class="fu">anova</span>(<span class="fu">lm</span>(<span class="fu">c</span>(<span class="fu">tapply</span>(GLYCO,<span class="fu">list</span>(TREAT,RAT),mean))[<span class="sc">!</span><span class="fu">is.na</span>(<span class="fu">c</span>(<span class="fu">tapply</span>(GLYCO,<span class="fu">list</span>(TREAT,RAT),mean)))<span class="sc">==</span><span class="cn">TRUE</span>]<span class="sc">~</span><span class="fu">factor</span>(<span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">2</span>,<span class="dv">3</span>,<span class="dv">1</span>,<span class="dv">2</span>,<span class="dv">3</span>))))</span></code></pre></div>
<pre><code>## Analysis of Variance Table
## 
## Response: c(tapply(GLYCO, list(TREAT, RAT), mean))[!is.na(c(tapply(GLYCO, 
## Response:     list(TREAT, RAT), mean))) == TRUE]
##                             Df Sum Sq Mean Sq F value Pr(&gt;F)
## factor(c(1, 2, 3, 1, 2, 3))  2   2.12    1.06  0.0081 0.9919
## Residuals                    3 390.42  130.14</code></pre>
<p>Analyzed this way we see that Treatment is not in fact significant, but averaging over all the liver samples precludes the possibility of looking at variation at the other scales of study (within rat, between measurements). Nested designs allow us to do just that.</p>
<p>To analyze nested models, we use the ‘/’ operator to show how things are nested, and we add a new error term to tell R how the errors are nested as well.</p>
<div class="sourceCode" id="cb793"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb793-1"><a href="week-12-lab.html#cb793-1" tabindex="-1"></a>model<span class="ot">&lt;-</span><span class="fu">aov</span>(GLYCO<span class="sc">~</span>TREAT<span class="sc">+</span><span class="fu">Error</span>(RAT<span class="sc">/</span>PREP))</span></code></pre></div>
<pre><code>## Warning in aov(GLYCO ~ TREAT + Error(RAT/PREP)): Error() model is singular</code></pre>
<div class="sourceCode" id="cb795"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb795-1"><a href="week-12-lab.html#cb795-1" tabindex="-1"></a><span class="fu">summary</span>(model)</span></code></pre></div>
<pre><code>## 
## Error: RAT
##           Df Sum Sq Mean Sq F value Pr(&gt;F)
## TREAT      2 1557.6   778.8   2.929  0.197
## Residuals  3  797.7   265.9               
## 
## Error: RAT:PREP
##           Df Sum Sq Mean Sq F value Pr(&gt;F)
## Residuals 12    594    49.5               
## 
## Error: Within
##           Df Sum Sq Mean Sq F value Pr(&gt;F)
## Residuals 18    381   21.17</code></pre>
<p>Note that if you leave the error term off, the sum of squares calculated are correct, but the F ratios are wrong and, as a result, the p-values are way too small.</p>
</div>
<div id="example-3-nested-design" class="section level2 hasAnchor" number="23.3">
<h2><span class="header-section-number">23.3</span> Example #3: Nested design<a href="week-12-lab.html#example-3-nested-design" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Case study taken from Logan (see Figure 2): “In an unusually detailed preparation for an Environmental Effects Statement for a proposed discharge of dairy wastes in the Curdies River, in western Victoria, a team of stream ecologists wanted to describe the basic patterns of variation in a stream invertebrate thought to be sensitive to nutrient enrichment. As an indicator species, they focused on a small flatworm, Dugesia, and started by sampling populations of this worm at a range of scales. They sampled in two season, they sampled three randomly chosen (well, haphazardly, because sites are nearly always chosen to be close to road access) sites. A total of six sites in all were visited, 3 in each season. At each site, they sampled six stones, and counted the number of flatworms on each stone.”
Why is this a nested design and not a factorial (crossed) design? Because the sites chosen in each season are not the same sites, they are randomly selected in each season depending on logistical constraints.</p>
<div class="sourceCode" id="cb797"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb797-1"><a href="week-12-lab.html#cb797-1" tabindex="-1"></a>worms<span class="ot">&lt;-</span><span class="fu">read.csv</span>(<span class="st">&quot;_data/flatworms.csv&quot;</span>,<span class="at">header=</span>T)</span>
<span id="cb797-2"><a href="week-12-lab.html#cb797-2" tabindex="-1"></a>worms<span class="sc">$</span>Site<span class="ot">&lt;-</span><span class="fu">factor</span>(worms<span class="sc">$</span>Site)</span></code></pre></div>
<p>Question: What are the main hypotheses being tested?</p>
<p><span class="math inline">\(H_{0}\)</span> for Effect #1: There is no effect of season on flatworm density</p>
<p><span class="math inline">\(H_{0}\)</span> for Effect #2: There is no added variance due to the random variable Sites</p>
<p>First, let’s check the assumption of normality by looking at boxplots of the data</p>
<div class="sourceCode" id="cb798"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb798-1"><a href="week-12-lab.html#cb798-1" tabindex="-1"></a><span class="fu">boxplot</span>(Density<span class="sc">~</span>Season,<span class="at">data=</span>worms)</span></code></pre></div>
<p><img src="Week-12-lab_files/figure-html/unnamed-chunk-14-1.png" width="672" /></p>
<p>We see that Winter has significantly more variance than Summer. What do we do? We try and transform Density so as to stabilize variance between two seasons. The original authors use a fourth-root transformation, so we will try that…</p>
<div class="sourceCode" id="cb799"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb799-1"><a href="week-12-lab.html#cb799-1" tabindex="-1"></a><span class="fu">boxplot</span>(Density<span class="sc">^</span>(<span class="dv">1</span><span class="sc">/</span><span class="dv">4</span>)<span class="sc">~</span>Season,<span class="at">data=</span>worms)</span></code></pre></div>
<p><img src="Week-12-lab_files/figure-html/unnamed-chunk-15-1.png" width="672" /></p>
<p>A log transformation would also have worked.There are strategies for finding the best transformation but we don’t have time to get into that.</p>
<p>Question: What are the correct F-ratios and the appropriate degrees of freedom?</p>
<p>(See Table 1)</p>
<p>Let’s fit the model in R:</p>
<div class="sourceCode" id="cb800"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb800-1"><a href="week-12-lab.html#cb800-1" tabindex="-1"></a>model2<span class="ot">&lt;-</span><span class="fu">aov</span>(Density<span class="sc">^</span>(<span class="dv">1</span><span class="sc">/</span><span class="dv">4</span>)<span class="sc">~</span>Season<span class="sc">+</span><span class="fu">Error</span>(Site),<span class="at">data=</span>worms)</span>
<span id="cb800-2"><a href="week-12-lab.html#cb800-2" tabindex="-1"></a><span class="fu">summary</span>(model2)</span></code></pre></div>
<pre><code>## 
## Error: Site
##           Df Sum Sq Mean Sq F value Pr(&gt;F)   
## Season     1  5.571   5.571    34.5 0.0042 **
## Residuals  4  0.646   0.161                  
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Error: Within
##           Df Sum Sq Mean Sq F value Pr(&gt;F)
## Residuals 30  4.556  0.1519</code></pre>
<div class="sourceCode" id="cb802"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb802-1"><a href="week-12-lab.html#cb802-1" tabindex="-1"></a><span class="fu">summary</span>(<span class="fu">lm</span>(model2))</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = model2)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -0.3811 -0.2618 -0.1381  0.1652  0.9023 
## 
## Coefficients: (1 not defined because of singularities)
##                    Estimate Std. Error t value Pr(&gt;|t|)   
## (Intercept)          0.3811     0.1591   2.396  0.02303 * 
## SeasonWINTER         0.7518     0.2250   3.342  0.00224 **
## Site2                0.1389     0.2250   0.618  0.54156   
## Site3               -0.2651     0.2250  -1.178  0.24798   
## Site4               -0.0303     0.2250  -0.135  0.89376   
## Site5               -0.2007     0.2250  -0.892  0.37955   
## Site6                    NA         NA      NA       NA   
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 0.3897 on 30 degrees of freedom
## Multiple R-squared:  0.5771, Adjusted R-squared:  0.5066 
## F-statistic: 8.188 on 5 and 30 DF,  p-value: 5.718e-05</code></pre>
<p><strong>Question: How do we interpret the model? The F-ratio for Season is significant - what does this mean biologically? If we were to go back and redesign the study to maximize power, what would we do?</strong></p>
<details>
<summary>
Click for Answer
</summary>
<span style="color: blueviolet;">
If a nested design was to be used, then since SITES are the replicates for the effect of SEASON, then power is maximized by having more sites. Whilst having more stones may increase the precision of the measure of Dugusia within a site, it will not improve the power of the test of SEASON.
</span>
</details>
<p>Let’s fit the model using the untransformed data just to compare:</p>
<div class="sourceCode" id="cb804"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb804-1"><a href="week-12-lab.html#cb804-1" tabindex="-1"></a>model3<span class="ot">&lt;-</span><span class="fu">aov</span>(Density<span class="sc">~</span>Season<span class="sc">+</span><span class="fu">Error</span>(Site),<span class="at">data=</span>worms)</span>
<span id="cb804-2"><a href="week-12-lab.html#cb804-2" tabindex="-1"></a><span class="fu">summary</span>(model3)</span></code></pre></div>
<pre><code>## 
## Error: Site
##           Df Sum Sq Mean Sq F value Pr(&gt;F)
## Season     1  36.81   36.81   3.918  0.119
## Residuals  4  37.58    9.40               
## 
## Error: Within
##           Df Sum Sq Mean Sq F value Pr(&gt;F)
## Residuals 30  203.9   6.798</code></pre>
<p>Now we get a grossly inflated level of significance for Season driven by the larger variance of the Winter densities.</p>
</div>
<div id="example-4-randomized-block-design" class="section level2 hasAnchor" number="23.4">
<h2><span class="header-section-number">23.4</span> Example #4: Randomized Block Design<a href="week-12-lab.html#example-4-randomized-block-design" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>(From Quinn, Keough, and Carey; see Figure 3) A plant pathologist wanted to examine the effects of two different strengths of tobacco virus on the number of lesions on tobacco leaves. She knew from pilot studies that leaves were inherently very variable in response to the virus. In an attempt to account for this leaf to leaf variability, both treatments were applied to each leaf. Eight individual leaves were divided in half, with half of each leaf incoculated with weak strength virus and the other half inoculated with strong virus.</p>
<p><strong>Question: What kind of analysis is this?</strong></p>
<details>
<summary>
Click for Answer
</summary>
<span style="color: blueviolet;">
A randomized block design, with Leaf as the “blocking factor”.
</span>
</details>
<p>So in this case, the leaves are considered the “blocks” and each treatment is represented once in each block. A completely randomized design would have had 16 leaves, with 8 whole leaves randomly allocated to each treatment.</p>
<div class="sourceCode" id="cb806"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb806-1"><a href="week-12-lab.html#cb806-1" tabindex="-1"></a>tobacco<span class="ot">&lt;-</span><span class="fu">read.csv</span>(<span class="st">&quot;_data/tobacco.csv&quot;</span>)</span>
<span id="cb806-2"><a href="week-12-lab.html#cb806-2" tabindex="-1"></a><span class="fu">head</span>(tobacco)</span></code></pre></div>
<pre><code>##   Leaf Treatment   Number
## 1   L1    Strong 35.89776
## 2   L1      Weak 25.01984
## 3   L2    Strong 34.11786
## 4   L2      Weak 23.16740
## 5   L3    Strong 35.70215
## 6   L3      Weak 24.12191</code></pre>
<p><strong>Question: What are the main hypotheses being tested?</strong></p>
<details>
<summary>
Click for Answer
</summary>
<p><span style="color: blueviolet;">
<span class="math inline">\(H_{0}\)</span> for Effect #1: There is no effect of treatment on lesion number within each leaf block.</p>
<p><span class="math inline">\(H_{0}\)</span> for Effect #2: There is no added variance due to the random variable Leaf. (In other words, there is no effect of the blocking factor leaf.)</p>
<p>We can’t actually test for an interaction between Block and Treatment in this design, but we can look at the data using an “Interaction plot”.</p>
<div class="sourceCode" id="cb808"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb808-1"><a href="week-12-lab.html#cb808-1" tabindex="-1"></a><span class="fu">boxplot</span>(Number<span class="sc">~</span><span class="fu">interaction</span>(Leaf,Treatment),<span class="at">data=</span>tobacco)</span></code></pre></div>
<p><img src="Week-12-lab_files/figure-html/unnamed-chunk-19-1.png" width="672" /></p>
The interaction plot suggests that there is some evidence of an interaction. Although the number of lesions appear to be greater in strongly innoculated leaves than the weakly innoculated leaves in most of the leaf pairs (blocks), this trend is either absent or reversed in two of the eight (1/4) of the leaf pairs. As a result, the test of block may not be reliable, and the power of the main test of treatment is reduced.
</span>
</details>
<p><strong>Question: What is the right R command to fit this model?</strong></p>
<details>
<summary>
Click for Answer
</summary>
<p><span style="color: blueviolet;"></p>
<div class="sourceCode" id="cb809"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb809-1"><a href="week-12-lab.html#cb809-1" tabindex="-1"></a>model4<span class="ot">&lt;-</span><span class="fu">aov</span>(Number<span class="sc">~</span>Treatment<span class="sc">+</span><span class="fu">Error</span>(Leaf<span class="sc">/</span>Treatment),<span class="at">data=</span>tobacco)</span>
<span id="cb809-2"><a href="week-12-lab.html#cb809-2" tabindex="-1"></a><span class="fu">summary</span>(model4)</span></code></pre></div>
<pre><code>## 
## Error: Leaf
##           Df Sum Sq Mean Sq F value Pr(&gt;F)
## Residuals  7  292.1   41.73               
## 
## Error: Leaf:Treatment
##           Df Sum Sq Mean Sq F value  Pr(&gt;F)   
## Treatment  1  248.3  248.34   17.17 0.00433 **
## Residuals  7  101.2   14.46                   
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
Note that Treatment is WITHIN Leaf, not the other way around.
</span>
</details>
<p><strong>Question: What are the relevant F-ratios here? </strong></p>
<details>
<summary>
Click for Answer
</summary>
<span style="color: blueviolet;">
Going back to our table for Blocked design, we see that the F-ratio is MS/MS_resid.
</span>
</details>
<p><strong>Question: What is the biological interpretation here?</strong></p>
<details>
<summary>
Click for Answer
</summary>
<span style="color: blueviolet;">
Strongly innoculated tobacco leaves were found to have significantly higher mean numbers of lesions than weakly innoculated leaves. Leaf pairs (blocks) explained substantial amounts of the variation and therefore probably contributed to the sensitivity of the main test of treatment - thereby justifying the blocking design over a completely randomized design.
</span>
</details>
<p>How would we fit this with a mixed model?</p>
<div class="sourceCode" id="cb811"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb811-1"><a href="week-12-lab.html#cb811-1" tabindex="-1"></a><span class="fu">library</span>(lme4)</span></code></pre></div>
<pre><code>## Loading required package: Matrix</code></pre>
<div class="sourceCode" id="cb813"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb813-1"><a href="week-12-lab.html#cb813-1" tabindex="-1"></a>model5<span class="ot">&lt;-</span><span class="fu">lmer</span>(Number<span class="sc">~</span>Treatment<span class="sc">+</span>(<span class="dv">1</span><span class="sc">|</span>Leaf),tobacco)</span>
<span id="cb813-2"><a href="week-12-lab.html#cb813-2" tabindex="-1"></a><span class="fu">summary</span>(model5)</span></code></pre></div>
<pre><code>## Linear mixed model fit by REML [&#39;lmerMod&#39;]
## Formula: Number ~ Treatment + (1 | Leaf)
##    Data: tobacco
## 
## REML criterion at convergence: 88.7
## 
## Scaled residuals: 
##      Min       1Q   Median       3Q      Max 
## -1.61850 -0.48453  0.01133  0.40900  1.42778 
## 
## Random effects:
##  Groups   Name        Variance Std.Dev.
##  Leaf     (Intercept) 13.63    3.692   
##  Residual             14.46    3.803   
## Number of obs: 16, groups:  Leaf, 8
## 
## Fixed effects:
##               Estimate Std. Error t value
## (Intercept)     34.940      1.874  18.645
## TreatmentWeak   -7.879      1.901  -4.144
## 
## Correlation of Fixed Effects:
##             (Intr)
## TreatmentWk -0.507</code></pre>
</div>
<div id="example-5-nested-design" class="section level2 hasAnchor" number="23.5">
<h2><span class="header-section-number">23.5</span> Example #5: Nested design<a href="week-12-lab.html#example-5-nested-design" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>In an experiment on eye color, each male fly is mated with four different female flies. Two offspring are born from each mating, and the intensity of eye color among these offspring are measured. The question is, how much variation in eye color is due to differences between females and how much is due to differences between males?</p>
<div class="sourceCode" id="cb815"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb815-1"><a href="week-12-lab.html#cb815-1" tabindex="-1"></a>flies<span class="ot">&lt;-</span><span class="fu">read.table</span>(<span class="st">&quot;_data/flies.txt&quot;</span>,<span class="at">header=</span>T)</span>
<span id="cb815-2"><a href="week-12-lab.html#cb815-2" tabindex="-1"></a>flies<span class="sc">$</span>male<span class="ot">&lt;-</span><span class="fu">factor</span>(flies<span class="sc">$</span>male)</span>
<span id="cb815-3"><a href="week-12-lab.html#cb815-3" tabindex="-1"></a>flies<span class="sc">$</span>female<span class="ot">&lt;-</span><span class="fu">factor</span>(flies<span class="sc">$</span>female)</span>
<span id="cb815-4"><a href="week-12-lab.html#cb815-4" tabindex="-1"></a>model6<span class="ot">&lt;-</span><span class="fu">aov</span>(eye<span class="sc">~</span>male<span class="sc">/</span>female<span class="sc">+</span><span class="fu">Error</span>(male<span class="sc">/</span>female),<span class="at">data=</span>flies)</span>
<span id="cb815-5"><a href="week-12-lab.html#cb815-5" tabindex="-1"></a><span class="fu">summary</span>(model6)</span></code></pre></div>
<pre><code>## 
## Error: male
##      Df Sum Sq Mean Sq
## male  2  665.7   332.8
## 
## Error: male:female
##             Df Sum Sq Mean Sq
## male:female  9   1721   191.2
## 
## Error: Within
##           Df Sum Sq Mean Sq F value Pr(&gt;F)
## Residuals 12  15.62   1.302</code></pre>
<p><strong>Question: What is the interpretation of this result?</strong></p>
<details>
<summary>
Click for Answer
</summary>
<span style="color: blueviolet;">
Females within male are much more important!
</span>
</details>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="week-12-lecture.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="week-13-lecture.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": null,
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
